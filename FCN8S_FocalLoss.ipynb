{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义VGG和FCN网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.vgg import VGG\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面开始定义网络模型\n",
    "# 先定义VGG结构\n",
    "\n",
    "# ranges 是用于方便获取和记录每个池化层得到的特征图\n",
    "# 例如vgg16，需要(0, 5)的原因是为方便记录第一个pooling层得到的输出(详见下面VGG定义)\n",
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6), (6, 11), (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# Vgg网络结构配置（数字代表经过卷积后的channel数，‘M’代表卷积层）\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由cfg构建vgg-Net的卷积层和池化层(block1-block5)\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面开始构建VGGnet\n",
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained=True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super().__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "\n",
    "        # 获取VGG模型训练好的参数，并加载（第一次执行需要下载一段时间）\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # 去掉vgg最后的全连接层(classifier)\n",
    "        if remove_fc:\n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "        # 利用之前定义的ranges获取每个maxpooling层输出的特征图\n",
    "        for idx, (begin, end) in enumerate(self.ranges):\n",
    "            # self.ranges = ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)) (vgg16 examples)\n",
    "            # vgg16有5个卷积块，每个卷积块的最后一层是pooling，即第0~4是卷积、激活、卷积、激活，第5层是池化\n",
    "            # 第三个卷积块是三次卷积三次激活后一次pooling\n",
    "            for layer in range(begin, end):\n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\" % (idx + 1)] = x\n",
    "        # output 为一个字典键x1d对应第一个maxpooling输出的特征图，x2...x5类推\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面由VGG构建FCN8s\n",
    "class FCN8s(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        \"\"\"pretrained_net:预训练的网络;\n",
    "        n_class:分类数\"\"\"\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.conv6 = nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  # maxpooling5的feature map (1/32)\n",
    "        x4 = output['x4']  # maxpooling4的feature map (1/16)\n",
    "        x3 = output['x3']  # maxpooling3的feature map (1/8)\n",
    "\n",
    "        score = self.relu(self.conv6(x5))  # conv6  size不变 (1/32)\n",
    "        score = self.relu(self.conv7(score))  # conv7  size不变 (1/32)\n",
    "        # score是conv7,升采样一次后变成1/16与x4相加\n",
    "        score = self.relu(self.deconv1(score))  # out_size = 2*in_size (1/16)\n",
    "        score = self.bn1(score + x4)\n",
    "        # score现在是1/16，升采样后变成1/8与x3相加\n",
    "        score = self.relu(self.deconv2(score))  # out_size = 2*in_size (1/8)\n",
    "        score = self.bn2(score + x3)\n",
    "        # score现在是1/8\n",
    "        score = self.bn3(self.relu(self.deconv3(score))) \n",
    "        # score现在是1/4\n",
    "        score = self.bn4(self.relu(self.deconv4(score)))  \n",
    "        # score现在是1/2\n",
    "        score = self.bn5(self.relu(self.deconv5(score)))  \n",
    "        # score现在是1/1，恢复到原来的尺寸\n",
    "        score = self.classifier(score)  \n",
    "        # size不变，使输出的channel等于类别数\n",
    "\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_road/training/image_2/umm_000000.png\n",
      "./data_road/training/gt_image_2/umm_road_000000.png\n"
     ]
    }
   ],
   "source": [
    "# 利用torch提供的Dataset类，定义我们自己的数据集\n",
    "import pandas as pd\n",
    "data = pd.read_csv('imgpath.csv')\n",
    "print(data.img_path[0])\n",
    "print(data.mask_path[0])\n",
    "class BagDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = data.img_path[idx]\n",
    "        imgA = cv2.imread(img_name)\n",
    "        imgA = cv2.resize(imgA, (640, 160))\n",
    "        mask_name = data.mask_path[idx]\n",
    "        imgB = cv2.imread(mask_name, 0)\n",
    "        imgB = cv2.resize(imgB, (640, 160))\n",
    "        imgB[imgB==76] = 1\n",
    "        imgB[imgB>1] = 2\n",
    "        imgB = imgB.astype('uint8')\n",
    "        imgB = torch.FloatTensor(imgB)\n",
    "        # print(imgB.shape)\n",
    "        if self.transform:\n",
    "            imgA = self.transform(imgA)\n",
    "        return imgA, imgB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练FCN8S网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练网络前定义函数用于计算Acc 和 mIou\n",
    "# 计算混淆矩阵\n",
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    # mask把符合分类属性的位置取出来\n",
    "    # label_true和label_pred中最大值均为n_class-1，\n",
    "    # np.bincount统计各个数出现的次数，返回长度为序列最大值+1，\n",
    "    # minlength是返回的最大长度，小于最大值+1时无效，此处minlength = n_class**2，和混淆矩阵尺寸相同\n",
    "    # 返回一个n_class行n_class列的混淆矩阵，行是实际值，列是预测值\n",
    "    # hist计算中最大值为(n_class-1)*n_class+n_class，即n_class**2，以n_class=3为例\n",
    "    # 两者相加=0，实际为0，表示预测为0，\n",
    "    # 两者相加=1，实际为0，表示预测为1，\n",
    "    # 两者相加=2，实际为0，表示预测为2，\n",
    "    # 两者相加=3，实际为1，表示预测为0，\n",
    "    # 两者相加=4，实际为1，表示预测为1，\n",
    "    # 两者相加=5，实际为1，表示预测为2，\n",
    "    # 两者相加=6，实际为2，表示预测为0，\n",
    "    # 两者相加=7，实际为2，表示预测为1，\n",
    "    # 两者相加=8，实际为2，表示预测为2，\n",
    "    # np.bincount用于统计各个数值的个数，reshape后就是混淆矩阵\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据混淆矩阵计算Acc和mIou\n",
    "def label_accuracy_score(label_trues, label_preds, n_class):\n",
    "    # 生成混淆矩阵形状的矩阵\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    # 计算各个批次结果的混淆矩阵和\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    # np.diag把对角线的值取出来（即分类正确的个数）求和，并除以总数，即正确率\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    # 忽略错误的情况下，计算每一类的正确率\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    # 忽略nan的求平均\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    # axis=1表示按行求和，表示实际某类的个数，\n",
    "    # axis=0表示按列求和，表示预测某类的个数，\n",
    "    # 相加之后正好多加了一次对角线的数，因此减去对角线\n",
    "    # 相除之后表示某个类别预测正确的占正确的和错误的总和的比值\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        iu = np.diag(hist) / (\n",
    "                hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist)\n",
    "        )\n",
    "    # 忽略nan的求平均\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    return acc, acc_cls, mean_iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, class_num, alpha=0.25, gamma=2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        if alpha is None:\n",
    "            self.alpha = torch.ones(class_num, 1)\n",
    "        else:\n",
    "            self.alpha = torch.tensor(alpha, requires_grad=True)\n",
    "        self.gamma = gamma\n",
    "        self.class_num = class_num\n",
    "        self.size_average = size_average\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs.shape = (N,C,H,W)\n",
    "        N,C,H,W = inputs.shape\n",
    "        # 将inputs的形状变成N,H,W,C\n",
    "        inputs = inputs.permute([0,2,3,1])\n",
    "        # 第三维进行softmax\n",
    "        P = F.softmax(inputs,dim=3) \n",
    "\n",
    "        # one hot start\n",
    "        # 生成和cross_entropy一样的shape形状,N,H,W,C\n",
    "        class_mask = inputs.data.new(N,H,W,self.class_num).fill_(0)  \n",
    "        # 需要更新，所以加入梯度计算\n",
    "        class_mask = class_mask.requires_grad_() \n",
    "        # 取得目标的索引，前三维要与class_mask一致\n",
    "        ids = targets.view(N,H,W,1) \n",
    "        # 利用scatter将ids的索引值将mask最后一个维度变成onehot，\n",
    "        class_mask.data.scatter_(3, ids.data, 1)\n",
    "        # one hot end\n",
    "\n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "\n",
    "        # 采用统一的alpha值\n",
    "        alpha = self.alpha\n",
    "        \n",
    "        probs = (P*class_mask).sum(3).view(N,H,W,1) \n",
    "        # 将softmax * one_hot格式，0的部分被消除，留下1的概率，即每个target的概率\n",
    "        \n",
    "        log_p = probs.log()\n",
    "        # 取得对数\n",
    "        \n",
    "        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p \n",
    "        # batch_loss就是取每一个batch的loss值\n",
    "        \n",
    "        \n",
    "        # 最终将每一个batch的loss加总后平均\n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(fcn_model,epo_num=50,n_class=3):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    fcn_model = fcn_model.to(device)\n",
    "    # 定义交叉熵损失函数\n",
    "    criterion = FocalLoss(n_class).to(device)\n",
    "    optimizer = optim.Adam(fcn_model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # 记录训练过程相关指标\n",
    "    all_train_iter_loss = []\n",
    "    all_test_iter_loss = []\n",
    "    test_Acc = []\n",
    "    test_mIou = []\n",
    "    # 记录开始时间\n",
    "    prev_time = datetime.now()\n",
    "\n",
    "    for epo in range(epo_num):\n",
    "\n",
    "        # 训练\n",
    "        train_loss = 0\n",
    "        fcn_model.train()\n",
    "        for index, (road, road_msk) in enumerate(train_dataloader):\n",
    "            # road.shape = torch.Size([4, 3, 160, 640])\n",
    "            # road_msk.shape = torch.Size([4,160,640])\n",
    "\n",
    "            road = road.to(device)\n",
    "            road_msk = road_msk.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = fcn_model(road)\n",
    "\n",
    "\n",
    "            loss = criterion(output, road_msk.long())\n",
    "            loss.backward()  \n",
    "            # 需要计算导数，则调用backward\n",
    "            iter_loss = loss.item()  \n",
    "            # .item()返回一个具体的值，一般用于loss和acc\n",
    "            all_train_iter_loss.append(iter_loss)\n",
    "            train_loss += iter_loss\n",
    "            optimizer.step()\n",
    "\n",
    "            output_np = output.cpu().detach().numpy().copy()\n",
    "            output_np = np.argmax(output_np, axis=1)\n",
    "            road_msk_np = road_msk.cpu().detach().numpy().copy()\n",
    "\n",
    "            # 每15个bacth，输出一次训练过程的数据\n",
    "            if np.mod(index, 15) == 0:\n",
    "                print('epoch {}, {}/{},train loss is {}'.format(epo, index, len(train_dataloader), iter_loss))\n",
    "\n",
    "        # 验证\n",
    "        test_loss = 0\n",
    "        fcn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for index, (road, road_msk) in enumerate(test_dataloader):\n",
    "                road = road.to(device)\n",
    "                road_msk = road_msk.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = fcn_model(road)\n",
    "                loss = criterion(output, road_msk.long())\n",
    "                iter_loss = loss.item()\n",
    "                all_test_iter_loss.append(iter_loss)\n",
    "                test_loss += iter_loss\n",
    "\n",
    "                # 把值小的那个位置取出来，即取出分类\n",
    "                output_np = output.cpu().detach().numpy().copy()\n",
    "                output_np = np.argmax(output_np, axis=1)\n",
    "                road_msk_np = road_msk.cpu().detach().numpy().copy()\n",
    "\n",
    "        cur_time = datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        prev_time = cur_time\n",
    "\n",
    "        print('<---------------------------------------------------->')\n",
    "        print('epoch: %d' % epo)\n",
    "        print('epoch train loss = %f, epoch test loss = %f, %s'\\\n",
    "              % (train_loss / len(train_dataloader), test_loss / len(test_dataloader), time_str))\n",
    "\n",
    "        acc, acc_cls, mean_iu = label_accuracy_score(road_msk_np, output_np, n_class)\n",
    "        test_Acc.append(acc)\n",
    "        test_mIou.append(mean_iu)\n",
    "\n",
    "        print('Acc = %f, mIou = %f' % (acc, mean_iu))\n",
    "        # 每5个epoch存储一次模型\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.mkdir('checkpoints')\n",
    "        if np.mod(epo+1, 5) == 0:\n",
    "            # 只存储模型参数\n",
    "            torch.save(fcn_model.state_dict(), 'checkpoints/fcn_model_Focalloss_{}.pth'.format(epo+1))\n",
    "            print('saveing checkpoints/fcn_model_{}.pth'.format(epo+1))\n",
    "\n",
    "    # 绘制训练过程数据\n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title('train_loss')\n",
    "    plt.plot(all_train_iter_loss)\n",
    "    plt.xlabel('batch')\n",
    "    plt.subplot(222)\n",
    "    plt.title('test_loss')\n",
    "    plt.plot(all_test_iter_loss)\n",
    "    plt.xlabel('batch')\n",
    "    plt.subplot(223)\n",
    "    plt.title('test_Acc')\n",
    "    plt.plot(test_Acc)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.subplot(224)\n",
    "    plt.title('test_mIou')\n",
    "    plt.plot(test_mIou)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, 0/65,train loss is 0.1482519805431366\n",
      "epoch 0, 15/65,train loss is 0.1034633070230484\n",
      "epoch 0, 30/65,train loss is 0.07473604381084442\n",
      "epoch 0, 45/65,train loss is 0.07466163486242294\n",
      "epoch 0, 60/65,train loss is 0.0467420369386673\n",
      "<---------------------------------------------------->\n",
      "epoch: 0\n",
      "epoch train loss = 0.079255, epoch test loss = 0.038646, Time 00:00:11\n",
      "Acc = 0.862686, mIou = 0.500026\n",
      "epoch 1, 0/65,train loss is 0.03732207044959068\n",
      "epoch 1, 15/65,train loss is 0.031950581818819046\n",
      "epoch 1, 30/65,train loss is 0.022999772801995277\n",
      "epoch 1, 45/65,train loss is 0.027500761672854424\n",
      "epoch 1, 60/65,train loss is 0.01887604221701622\n",
      "<---------------------------------------------------->\n",
      "epoch: 1\n",
      "epoch train loss = 0.032283, epoch test loss = 0.024352, Time 00:00:11\n",
      "Acc = 0.908936, mIou = 0.550208\n",
      "epoch 2, 0/65,train loss is 0.021489514037966728\n",
      "epoch 2, 15/65,train loss is 0.0276227667927742\n",
      "epoch 2, 30/65,train loss is 0.028374748304486275\n",
      "epoch 2, 45/65,train loss is 0.021597780287265778\n",
      "epoch 2, 60/65,train loss is 0.01793786883354187\n",
      "<---------------------------------------------------->\n",
      "epoch: 2\n",
      "epoch train loss = 0.020240, epoch test loss = 0.021463, Time 00:00:11\n",
      "Acc = 0.922354, mIou = 0.481654\n",
      "epoch 3, 0/65,train loss is 0.016212500631809235\n",
      "epoch 3, 15/65,train loss is 0.013293921947479248\n",
      "epoch 3, 30/65,train loss is 0.016560647636651993\n",
      "epoch 3, 45/65,train loss is 0.01482906099408865\n",
      "epoch 3, 60/65,train loss is 0.01656673662364483\n",
      "<---------------------------------------------------->\n",
      "epoch: 3\n",
      "epoch train loss = 0.017002, epoch test loss = 0.018785, Time 00:00:11\n",
      "Acc = 0.880752, mIou = 0.598023\n",
      "epoch 4, 0/65,train loss is 0.012549660168588161\n",
      "epoch 4, 15/65,train loss is 0.018973559141159058\n",
      "epoch 4, 30/65,train loss is 0.015105747617781162\n",
      "epoch 4, 45/65,train loss is 0.014796466566622257\n",
      "epoch 4, 60/65,train loss is 0.009629113599658012\n",
      "<---------------------------------------------------->\n",
      "epoch: 4\n",
      "epoch train loss = 0.014688, epoch test loss = 0.018222, Time 00:00:11\n",
      "Acc = 0.936455, mIou = 0.632168\n",
      "saveing checkpoints/fcn_model_5.pth\n",
      "epoch 5, 0/65,train loss is 0.01110501866787672\n",
      "epoch 5, 15/65,train loss is 0.010151177644729614\n",
      "epoch 5, 30/65,train loss is 0.012342371977865696\n",
      "epoch 5, 45/65,train loss is 0.012661688961088657\n",
      "epoch 5, 60/65,train loss is 0.012905998155474663\n",
      "<---------------------------------------------------->\n",
      "epoch: 5\n",
      "epoch train loss = 0.013094, epoch test loss = 0.019267, Time 00:00:11\n",
      "Acc = 0.904463, mIou = 0.491013\n",
      "epoch 6, 0/65,train loss is 0.011069968342781067\n",
      "epoch 6, 15/65,train loss is 0.01854732260107994\n",
      "epoch 6, 30/65,train loss is 0.014382509514689445\n",
      "epoch 6, 45/65,train loss is 0.011706355959177017\n",
      "epoch 6, 60/65,train loss is 0.00904214009642601\n",
      "<---------------------------------------------------->\n",
      "epoch: 6\n",
      "epoch train loss = 0.011846, epoch test loss = 0.021886, Time 00:00:11\n",
      "Acc = 0.911465, mIou = 0.515017\n",
      "epoch 7, 0/65,train loss is 0.012788769789040089\n",
      "epoch 7, 15/65,train loss is 0.006962798535823822\n",
      "epoch 7, 30/65,train loss is 0.01108174491673708\n",
      "epoch 7, 45/65,train loss is 0.007647896185517311\n",
      "epoch 7, 60/65,train loss is 0.008909264579415321\n",
      "<---------------------------------------------------->\n",
      "epoch: 7\n",
      "epoch train loss = 0.010711, epoch test loss = 0.021021, Time 00:00:11\n",
      "Acc = 0.941543, mIou = 0.576483\n",
      "epoch 8, 0/65,train loss is 0.009657388553023338\n",
      "epoch 8, 15/65,train loss is 0.007578568067401648\n",
      "epoch 8, 30/65,train loss is 0.008937185630202293\n",
      "epoch 8, 45/65,train loss is 0.008756842464208603\n",
      "epoch 8, 60/65,train loss is 0.009232318960130215\n",
      "<---------------------------------------------------->\n",
      "epoch: 8\n",
      "epoch train loss = 0.009634, epoch test loss = 0.021934, Time 00:00:11\n",
      "Acc = 0.898096, mIou = 0.664540\n",
      "epoch 9, 0/65,train loss is 0.005804196931421757\n",
      "epoch 9, 15/65,train loss is 0.007998700253665447\n",
      "epoch 9, 30/65,train loss is 0.007393601816147566\n",
      "epoch 9, 45/65,train loss is 0.014886888675391674\n",
      "epoch 9, 60/65,train loss is 0.015272440388798714\n",
      "<---------------------------------------------------->\n",
      "epoch: 9\n",
      "epoch train loss = 0.008660, epoch test loss = 0.021105, Time 00:00:11\n",
      "Acc = 0.944121, mIou = 0.588182\n",
      "saveing checkpoints/fcn_model_10.pth\n",
      "epoch 10, 0/65,train loss is 0.008495884947478771\n",
      "epoch 10, 15/65,train loss is 0.006722277030348778\n",
      "epoch 10, 30/65,train loss is 0.009662149474024773\n",
      "epoch 10, 45/65,train loss is 0.006584732793271542\n",
      "epoch 10, 60/65,train loss is 0.004912928212434053\n",
      "<---------------------------------------------------->\n",
      "epoch: 10\n",
      "epoch train loss = 0.007814, epoch test loss = 0.021169, Time 00:00:11\n",
      "Acc = 0.945947, mIou = 0.665803\n",
      "epoch 11, 0/65,train loss is 0.006420640740543604\n",
      "epoch 11, 15/65,train loss is 0.005294728092849255\n",
      "epoch 11, 30/65,train loss is 0.006909121759235859\n",
      "epoch 11, 45/65,train loss is 0.004303834401071072\n",
      "epoch 11, 60/65,train loss is 0.008875912055373192\n",
      "<---------------------------------------------------->\n",
      "epoch: 11\n",
      "epoch train loss = 0.006400, epoch test loss = 0.023653, Time 00:00:11\n",
      "Acc = 0.938662, mIou = 0.558281\n",
      "epoch 12, 0/65,train loss is 0.004791263025254011\n",
      "epoch 12, 15/65,train loss is 0.005133644677698612\n",
      "epoch 12, 30/65,train loss is 0.005463847890496254\n",
      "epoch 12, 45/65,train loss is 0.006000012159347534\n",
      "epoch 12, 60/65,train loss is 0.006575538776814938\n",
      "<---------------------------------------------------->\n",
      "epoch: 12\n",
      "epoch train loss = 0.005377, epoch test loss = 0.024092, Time 00:00:11\n",
      "Acc = 0.919814, mIou = 0.706197\n",
      "epoch 13, 0/65,train loss is 0.004258785396814346\n",
      "epoch 13, 15/65,train loss is 0.004541848786175251\n",
      "epoch 13, 30/65,train loss is 0.004698500037193298\n",
      "epoch 13, 45/65,train loss is 0.005685874260962009\n",
      "epoch 13, 60/65,train loss is 0.004406018182635307\n",
      "<---------------------------------------------------->\n",
      "epoch: 13\n",
      "epoch train loss = 0.004795, epoch test loss = 0.026347, Time 00:00:11\n",
      "Acc = 0.894814, mIou = 0.431547\n",
      "epoch 14, 0/65,train loss is 0.004239024594426155\n",
      "epoch 14, 15/65,train loss is 0.006430043838918209\n",
      "epoch 14, 30/65,train loss is 0.005296769551932812\n",
      "epoch 14, 45/65,train loss is 0.0035843884106725454\n",
      "epoch 14, 60/65,train loss is 0.0054718125611543655\n",
      "<---------------------------------------------------->\n",
      "epoch: 14\n",
      "epoch train loss = 0.004389, epoch test loss = 0.025945, Time 00:00:11\n",
      "Acc = 0.913770, mIou = 0.590027\n",
      "saveing checkpoints/fcn_model_15.pth\n",
      "epoch 15, 0/65,train loss is 0.0029597263783216476\n",
      "epoch 15, 15/65,train loss is 0.003616809844970703\n",
      "epoch 15, 30/65,train loss is 0.005238757003098726\n",
      "epoch 15, 45/65,train loss is 0.003238300560042262\n",
      "epoch 15, 60/65,train loss is 0.0035851954016834497\n",
      "<---------------------------------------------------->\n",
      "epoch: 15\n",
      "epoch train loss = 0.004031, epoch test loss = 0.029744, Time 00:00:11\n",
      "Acc = 0.921025, mIou = 0.505883\n",
      "epoch 16, 0/65,train loss is 0.0025734559167176485\n",
      "epoch 16, 15/65,train loss is 0.002174569061025977\n",
      "epoch 16, 30/65,train loss is 0.0034159612841904163\n",
      "epoch 16, 45/65,train loss is 0.005172131583094597\n",
      "epoch 16, 60/65,train loss is 0.004606615286320448\n",
      "<---------------------------------------------------->\n",
      "epoch: 16\n",
      "epoch train loss = 0.003610, epoch test loss = 0.029222, Time 00:00:11\n",
      "Acc = 0.939043, mIou = 0.553565\n",
      "epoch 17, 0/65,train loss is 0.0036965608596801758\n",
      "epoch 17, 15/65,train loss is 0.0040781437419354916\n",
      "epoch 17, 30/65,train loss is 0.0026858695782721043\n",
      "epoch 17, 45/65,train loss is 0.0030855368822813034\n",
      "epoch 17, 60/65,train loss is 0.003536705859005451\n",
      "<---------------------------------------------------->\n",
      "epoch: 17\n",
      "epoch train loss = 0.003420, epoch test loss = 0.029199, Time 00:00:11\n",
      "Acc = 0.878496, mIou = 0.431347\n",
      "epoch 18, 0/65,train loss is 0.0026846658438444138\n",
      "epoch 18, 15/65,train loss is 0.002260451205074787\n",
      "epoch 18, 30/65,train loss is 0.002139078453183174\n",
      "epoch 18, 45/65,train loss is 0.003163298824802041\n",
      "epoch 18, 60/65,train loss is 0.0038061526138335466\n",
      "<---------------------------------------------------->\n",
      "epoch: 18\n",
      "epoch train loss = 0.003025, epoch test loss = 0.031421, Time 00:00:11\n",
      "Acc = 0.894131, mIou = 0.610943\n",
      "epoch 19, 0/65,train loss is 0.002905515721067786\n",
      "epoch 19, 15/65,train loss is 0.0024121275637298822\n",
      "epoch 19, 30/65,train loss is 0.002275855513289571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, 45/65,train loss is 0.0031582596711814404\n",
      "epoch 19, 60/65,train loss is 0.0021992307156324387\n",
      "<---------------------------------------------------->\n",
      "epoch: 19\n",
      "epoch train loss = 0.002881, epoch test loss = 0.032578, Time 00:00:11\n",
      "Acc = 0.914570, mIou = 0.522164\n",
      "saveing checkpoints/fcn_model_20.pth\n",
      "epoch 20, 0/65,train loss is 0.002353757619857788\n",
      "epoch 20, 15/65,train loss is 0.0022241147235035896\n",
      "epoch 20, 30/65,train loss is 0.0025553833693265915\n",
      "epoch 20, 45/65,train loss is 0.0036506205797195435\n",
      "epoch 20, 60/65,train loss is 0.0016726806061342359\n",
      "<---------------------------------------------------->\n",
      "epoch: 20\n",
      "epoch train loss = 0.002653, epoch test loss = 0.033305, Time 00:00:11\n",
      "Acc = 0.915752, mIou = 0.464182\n",
      "epoch 21, 0/65,train loss is 0.0015846508322283626\n",
      "epoch 21, 15/65,train loss is 0.0017126506427302957\n",
      "epoch 21, 30/65,train loss is 0.002124866470694542\n",
      "epoch 21, 45/65,train loss is 0.002521326532587409\n",
      "epoch 21, 60/65,train loss is 0.002857575658708811\n",
      "<---------------------------------------------------->\n",
      "epoch: 21\n",
      "epoch train loss = 0.002349, epoch test loss = 0.034655, Time 00:00:11\n",
      "Acc = 0.911387, mIou = 0.478843\n",
      "epoch 22, 0/65,train loss is 0.0017099770484492183\n",
      "epoch 22, 15/65,train loss is 0.0012124008499085903\n",
      "epoch 22, 30/65,train loss is 0.001689557684585452\n",
      "epoch 22, 45/65,train loss is 0.0025118349585682154\n",
      "epoch 22, 60/65,train loss is 0.0026670964434742928\n",
      "<---------------------------------------------------->\n",
      "epoch: 22\n",
      "epoch train loss = 0.002255, epoch test loss = 0.032955, Time 00:00:11\n",
      "Acc = 0.935137, mIou = 0.734949\n",
      "epoch 23, 0/65,train loss is 0.0016061959322541952\n",
      "epoch 23, 15/65,train loss is 0.00217517395503819\n",
      "epoch 23, 30/65,train loss is 0.001826781197451055\n",
      "epoch 23, 45/65,train loss is 0.002675115130841732\n",
      "epoch 23, 60/65,train loss is 0.00190357759129256\n",
      "<---------------------------------------------------->\n",
      "epoch: 23\n",
      "epoch train loss = 0.002240, epoch test loss = 0.035514, Time 00:00:11\n",
      "Acc = 0.911104, mIou = 0.639254\n",
      "epoch 24, 0/65,train loss is 0.003010644344612956\n",
      "epoch 24, 15/65,train loss is 0.0020327221136540174\n",
      "epoch 24, 30/65,train loss is 0.0017774266889318824\n",
      "epoch 24, 45/65,train loss is 0.0017533560749143362\n",
      "epoch 24, 60/65,train loss is 0.001789995119906962\n",
      "<---------------------------------------------------->\n",
      "epoch: 24\n",
      "epoch train loss = 0.002089, epoch test loss = 0.030978, Time 00:00:11\n",
      "Acc = 0.943809, mIou = 0.563903\n",
      "saveing checkpoints/fcn_model_25.pth\n",
      "epoch 25, 0/65,train loss is 0.0022526169195771217\n",
      "epoch 25, 15/65,train loss is 0.0023301993496716022\n",
      "epoch 25, 30/65,train loss is 0.0017673439579084516\n",
      "epoch 25, 45/65,train loss is 0.0021110193338245153\n",
      "epoch 25, 60/65,train loss is 0.001596379792317748\n",
      "<---------------------------------------------------->\n",
      "epoch: 25\n",
      "epoch train loss = 0.002015, epoch test loss = 0.037451, Time 00:00:11\n",
      "Acc = 0.893760, mIou = 0.612529\n",
      "epoch 26, 0/65,train loss is 0.0013709862250834703\n",
      "epoch 26, 15/65,train loss is 0.0011895319912582636\n",
      "epoch 26, 30/65,train loss is 0.002216199180111289\n",
      "epoch 26, 45/65,train loss is 0.0014561235439032316\n",
      "epoch 26, 60/65,train loss is 0.0017738675232976675\n",
      "<---------------------------------------------------->\n",
      "epoch: 26\n",
      "epoch train loss = 0.001832, epoch test loss = 0.038037, Time 00:00:11\n",
      "Acc = 0.904346, mIou = 0.456233\n",
      "epoch 27, 0/65,train loss is 0.0015527945943176746\n",
      "epoch 27, 15/65,train loss is 0.002088035922497511\n",
      "epoch 27, 30/65,train loss is 0.0016965040704235435\n",
      "epoch 27, 45/65,train loss is 0.0009678179048933089\n",
      "epoch 27, 60/65,train loss is 0.00250939535908401\n",
      "<---------------------------------------------------->\n",
      "epoch: 27\n",
      "epoch train loss = 0.001715, epoch test loss = 0.038282, Time 00:00:11\n",
      "Acc = 0.914473, mIou = 0.486490\n",
      "epoch 28, 0/65,train loss is 0.0015955453272908926\n",
      "epoch 28, 15/65,train loss is 0.0015832752687856555\n",
      "epoch 28, 30/65,train loss is 0.001226692576892674\n",
      "epoch 28, 45/65,train loss is 0.0015547722578048706\n",
      "epoch 28, 60/65,train loss is 0.001397384679876268\n",
      "<---------------------------------------------------->\n",
      "epoch: 28\n",
      "epoch train loss = 0.001745, epoch test loss = 0.035809, Time 00:00:11\n",
      "Acc = 0.944492, mIou = 0.574874\n",
      "epoch 29, 0/65,train loss is 0.0015515079721808434\n",
      "epoch 29, 15/65,train loss is 0.0012666910188272595\n",
      "epoch 29, 30/65,train loss is 0.0019344647880643606\n",
      "epoch 29, 45/65,train loss is 0.0021097096614539623\n",
      "epoch 29, 60/65,train loss is 0.0016564186662435532\n",
      "<---------------------------------------------------->\n",
      "epoch: 29\n",
      "epoch train loss = 0.001646, epoch test loss = 0.035483, Time 00:00:11\n",
      "Acc = 0.951699, mIou = 0.578247\n",
      "saveing checkpoints/fcn_model_30.pth\n",
      "epoch 30, 0/65,train loss is 0.001082003815099597\n",
      "epoch 30, 15/65,train loss is 0.0022652314510196447\n",
      "epoch 30, 30/65,train loss is 0.0016349251382052898\n",
      "epoch 30, 45/65,train loss is 0.0012807819293811917\n",
      "epoch 30, 60/65,train loss is 0.0018389616161584854\n",
      "<---------------------------------------------------->\n",
      "epoch: 30\n",
      "epoch train loss = 0.001596, epoch test loss = 0.040005, Time 00:00:11\n",
      "Acc = 0.897842, mIou = 0.633748\n",
      "epoch 31, 0/65,train loss is 0.0017419969663023949\n",
      "epoch 31, 15/65,train loss is 0.0011142917210236192\n",
      "epoch 31, 30/65,train loss is 0.0018199083860963583\n",
      "epoch 31, 45/65,train loss is 0.0009123582276515663\n",
      "epoch 31, 60/65,train loss is 0.001718913554213941\n",
      "<---------------------------------------------------->\n",
      "epoch: 31\n",
      "epoch train loss = 0.001595, epoch test loss = 0.032894, Time 00:00:11\n",
      "Acc = 0.983447, mIou = 0.806478\n",
      "epoch 32, 0/65,train loss is 0.0018880321877077222\n",
      "epoch 32, 15/65,train loss is 0.001992195611819625\n",
      "epoch 32, 30/65,train loss is 0.0016376437852159142\n",
      "epoch 32, 45/65,train loss is 0.0022130056750029325\n",
      "epoch 32, 60/65,train loss is 0.0021317261271178722\n",
      "<---------------------------------------------------->\n",
      "epoch: 32\n",
      "epoch train loss = 0.001582, epoch test loss = 0.038698, Time 00:00:11\n",
      "Acc = 0.933652, mIou = 0.540251\n",
      "epoch 33, 0/65,train loss is 0.0013780564768239856\n",
      "epoch 33, 15/65,train loss is 0.0011519507970660925\n",
      "epoch 33, 30/65,train loss is 0.0017578569240868092\n",
      "epoch 33, 45/65,train loss is 0.0013355916598811746\n",
      "epoch 33, 60/65,train loss is 0.0011800637003034353\n",
      "<---------------------------------------------------->\n",
      "epoch: 33\n",
      "epoch train loss = 0.001430, epoch test loss = 0.043560, Time 00:00:11\n",
      "Acc = 0.884375, mIou = 0.462983\n",
      "epoch 34, 0/65,train loss is 0.0024616196751594543\n",
      "epoch 34, 15/65,train loss is 0.0011879437370225787\n",
      "epoch 34, 30/65,train loss is 0.0012480331351980567\n",
      "epoch 34, 45/65,train loss is 0.0009311728645116091\n",
      "epoch 34, 60/65,train loss is 0.0008591813966631889\n",
      "<---------------------------------------------------->\n",
      "epoch: 34\n",
      "epoch train loss = 0.001312, epoch test loss = 0.041643, Time 00:00:11\n",
      "Acc = 0.893857, mIou = 0.461325\n",
      "saveing checkpoints/fcn_model_35.pth\n",
      "epoch 35, 0/65,train loss is 0.0008987945038825274\n",
      "epoch 35, 15/65,train loss is 0.000746008416172117\n",
      "epoch 35, 30/65,train loss is 0.0010574021143838763\n",
      "epoch 35, 45/65,train loss is 0.0010599276283755898\n",
      "epoch 35, 60/65,train loss is 0.0013212466146796942\n",
      "<---------------------------------------------------->\n",
      "epoch: 35\n",
      "epoch train loss = 0.001356, epoch test loss = 0.041816, Time 00:00:11\n",
      "Acc = 0.912471, mIou = 0.517745\n",
      "epoch 36, 0/65,train loss is 0.0011447551660239697\n",
      "epoch 36, 15/65,train loss is 0.0013756226981058717\n",
      "epoch 36, 30/65,train loss is 0.0017685843631625175\n",
      "epoch 36, 45/65,train loss is 0.001040969742462039\n",
      "epoch 36, 60/65,train loss is 0.001572249224409461\n",
      "<---------------------------------------------------->\n",
      "epoch: 36\n",
      "epoch train loss = 0.001235, epoch test loss = 0.039449, Time 00:00:11\n",
      "Acc = 0.936875, mIou = 0.657662\n",
      "epoch 37, 0/65,train loss is 0.0009048552019521594\n",
      "epoch 37, 15/65,train loss is 0.0008962481515482068\n",
      "epoch 37, 30/65,train loss is 0.0012176145100966096\n",
      "epoch 37, 45/65,train loss is 0.0009112124680541456\n",
      "epoch 37, 60/65,train loss is 0.000884781067725271\n",
      "<---------------------------------------------------->\n",
      "epoch: 37\n",
      "epoch train loss = 0.001164, epoch test loss = 0.043939, Time 00:00:11\n",
      "Acc = 0.925400, mIou = 0.571801\n",
      "epoch 38, 0/65,train loss is 0.0009953835979104042\n",
      "epoch 38, 15/65,train loss is 0.0009644536185078323\n",
      "epoch 38, 30/65,train loss is 0.001840384560637176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, 45/65,train loss is 0.0008840766968205571\n",
      "epoch 38, 60/65,train loss is 0.0013680087868124247\n",
      "<---------------------------------------------------->\n",
      "epoch: 38\n",
      "epoch train loss = 0.001224, epoch test loss = 0.043661, Time 00:00:11\n",
      "Acc = 0.890312, mIou = 0.625549\n",
      "epoch 39, 0/65,train loss is 0.0012106506619602442\n",
      "epoch 39, 15/65,train loss is 0.0011192697566002607\n",
      "epoch 39, 30/65,train loss is 0.0006747909355908632\n",
      "epoch 39, 45/65,train loss is 0.0009213353623636067\n",
      "epoch 39, 60/65,train loss is 0.0019948421977460384\n",
      "<---------------------------------------------------->\n",
      "epoch: 39\n",
      "epoch train loss = 0.001237, epoch test loss = 0.038574, Time 00:00:11\n",
      "Acc = 0.969424, mIou = 0.613282\n",
      "saveing checkpoints/fcn_model_40.pth\n",
      "epoch 40, 0/65,train loss is 0.001145042129792273\n",
      "epoch 40, 15/65,train loss is 0.0011476107174530625\n",
      "epoch 40, 30/65,train loss is 0.0010465494124218822\n",
      "epoch 40, 45/65,train loss is 0.0009021381847560406\n",
      "epoch 40, 60/65,train loss is 0.0013772224774584174\n",
      "<---------------------------------------------------->\n",
      "epoch: 40\n",
      "epoch train loss = 0.001323, epoch test loss = 0.044989, Time 00:00:11\n",
      "Acc = 0.894717, mIou = 0.635589\n",
      "epoch 41, 0/65,train loss is 0.0008798203198239207\n",
      "epoch 41, 15/65,train loss is 0.0010938957566395402\n",
      "epoch 41, 30/65,train loss is 0.0011325370287522674\n",
      "epoch 41, 45/65,train loss is 0.000810455356258899\n",
      "epoch 41, 60/65,train loss is 0.0007005648221820593\n",
      "<---------------------------------------------------->\n",
      "epoch: 41\n",
      "epoch train loss = 0.001278, epoch test loss = 0.038806, Time 00:00:11\n",
      "Acc = 0.967695, mIou = 0.647749\n",
      "epoch 42, 0/65,train loss is 0.001450941781513393\n",
      "epoch 42, 15/65,train loss is 0.0010517638875171542\n",
      "epoch 42, 30/65,train loss is 0.003914565313607454\n",
      "epoch 42, 45/65,train loss is 0.0027497124392539263\n",
      "epoch 42, 60/65,train loss is 0.0021597156301140785\n",
      "<---------------------------------------------------->\n",
      "epoch: 42\n",
      "epoch train loss = 0.001947, epoch test loss = 0.031353, Time 00:00:11\n",
      "Acc = 0.976006, mIou = 0.695298\n",
      "epoch 43, 0/65,train loss is 0.0016587942373007536\n",
      "epoch 43, 15/65,train loss is 0.0024490978103131056\n",
      "epoch 43, 30/65,train loss is 0.0043745143339037895\n",
      "epoch 43, 45/65,train loss is 0.003209806978702545\n",
      "epoch 43, 60/65,train loss is 0.0018847347237169743\n",
      "<---------------------------------------------------->\n",
      "epoch: 43\n",
      "epoch train loss = 0.003125, epoch test loss = 0.031942, Time 00:00:11\n",
      "Acc = 0.919990, mIou = 0.625901\n",
      "epoch 44, 0/65,train loss is 0.002745823236182332\n",
      "epoch 44, 15/65,train loss is 0.004770525731146336\n",
      "epoch 44, 30/65,train loss is 0.0043626585975289345\n",
      "epoch 44, 45/65,train loss is 0.002952982671558857\n",
      "epoch 44, 60/65,train loss is 0.002868038835003972\n",
      "<---------------------------------------------------->\n",
      "epoch: 44\n",
      "epoch train loss = 0.003769, epoch test loss = 0.038453, Time 00:00:11\n",
      "Acc = 0.848457, mIou = 0.413067\n",
      "saveing checkpoints/fcn_model_45.pth\n",
      "epoch 45, 0/65,train loss is 0.002587097929790616\n",
      "epoch 45, 15/65,train loss is 0.001032699947245419\n",
      "epoch 45, 30/65,train loss is 0.0017359843477606773\n",
      "epoch 45, 45/65,train loss is 0.00167830940335989\n",
      "epoch 45, 60/65,train loss is 0.0018184491200372577\n",
      "<---------------------------------------------------->\n",
      "epoch: 45\n",
      "epoch train loss = 0.001949, epoch test loss = 0.040316, Time 00:00:11\n",
      "Acc = 0.866074, mIou = 0.596415\n",
      "epoch 46, 0/65,train loss is 0.002488801022991538\n",
      "epoch 46, 15/65,train loss is 0.0013791588135063648\n",
      "epoch 46, 30/65,train loss is 0.001025488949380815\n",
      "epoch 46, 45/65,train loss is 0.0011285289656370878\n",
      "epoch 46, 60/65,train loss is 0.0013219635002315044\n",
      "<---------------------------------------------------->\n",
      "epoch: 46\n",
      "epoch train loss = 0.001328, epoch test loss = 0.042415, Time 00:00:11\n",
      "Acc = 0.889229, mIou = 0.607945\n",
      "epoch 47, 0/65,train loss is 0.00100874959025532\n",
      "epoch 47, 15/65,train loss is 0.0017131211934611201\n",
      "epoch 47, 30/65,train loss is 0.0010874612489715219\n",
      "epoch 47, 45/65,train loss is 0.0010433710413053632\n",
      "epoch 47, 60/65,train loss is 0.001003643381409347\n",
      "<---------------------------------------------------->\n",
      "epoch: 47\n",
      "epoch train loss = 0.000993, epoch test loss = 0.044215, Time 00:00:11\n",
      "Acc = 0.922783, mIou = 0.510309\n",
      "epoch 48, 0/65,train loss is 0.0008208666695281863\n",
      "epoch 48, 15/65,train loss is 0.0007666635210625827\n",
      "epoch 48, 30/65,train loss is 0.000916329154279083\n",
      "epoch 48, 45/65,train loss is 0.0007619623793289065\n",
      "epoch 48, 60/65,train loss is 0.0009640008211135864\n",
      "<---------------------------------------------------->\n",
      "epoch: 48\n",
      "epoch train loss = 0.000872, epoch test loss = 0.044247, Time 00:00:11\n",
      "Acc = 0.949766, mIou = 0.676810\n",
      "epoch 49, 0/65,train loss is 0.0007134558982215822\n",
      "epoch 49, 15/65,train loss is 0.0007642039563506842\n",
      "epoch 49, 30/65,train loss is 0.0010673230281099677\n",
      "epoch 49, 45/65,train loss is 0.0015098191797733307\n",
      "epoch 49, 60/65,train loss is 0.0009543129126541317\n",
      "<---------------------------------------------------->\n",
      "epoch: 49\n",
      "epoch train loss = 0.000843, epoch test loss = 0.048307, Time 00:00:11\n",
      "Acc = 0.923330, mIou = 0.511494\n",
      "saveing checkpoints/fcn_model_50.pth\n",
      "epoch 50, 0/65,train loss is 0.0005025307182222605\n",
      "epoch 50, 15/65,train loss is 0.0008234578417614102\n",
      "epoch 50, 30/65,train loss is 0.0007156732608564198\n",
      "epoch 50, 45/65,train loss is 0.000941395468544215\n",
      "epoch 50, 60/65,train loss is 0.0007507439004257321\n",
      "<---------------------------------------------------->\n",
      "epoch: 50\n",
      "epoch train loss = 0.000787, epoch test loss = 0.046612, Time 00:00:11\n",
      "Acc = 0.927783, mIou = 0.550262\n",
      "epoch 51, 0/65,train loss is 0.0005198376602493227\n",
      "epoch 51, 15/65,train loss is 0.0006314809434115887\n",
      "epoch 51, 30/65,train loss is 0.0007193222991190851\n",
      "epoch 51, 45/65,train loss is 0.0006182264187373221\n",
      "epoch 51, 60/65,train loss is 0.0009345551952719688\n",
      "<---------------------------------------------------->\n",
      "epoch: 51\n",
      "epoch train loss = 0.000768, epoch test loss = 0.045038, Time 00:00:11\n",
      "Acc = 0.954023, mIou = 0.580972\n",
      "epoch 52, 0/65,train loss is 0.0006550822872668505\n",
      "epoch 52, 15/65,train loss is 0.0008388742571696639\n",
      "epoch 52, 30/65,train loss is 0.0009072139509953558\n",
      "epoch 52, 45/65,train loss is 0.0008693663403391838\n",
      "epoch 52, 60/65,train loss is 0.0005704313516616821\n",
      "<---------------------------------------------------->\n",
      "epoch: 52\n",
      "epoch train loss = 0.000757, epoch test loss = 0.049920, Time 00:00:11\n",
      "Acc = 0.925215, mIou = 0.709356\n",
      "epoch 53, 0/65,train loss is 0.0007115670596249402\n",
      "epoch 53, 15/65,train loss is 0.0007872344576753676\n",
      "epoch 53, 30/65,train loss is 0.00042964809108525515\n",
      "epoch 53, 45/65,train loss is 0.0008331284625455737\n",
      "epoch 53, 60/65,train loss is 0.0008588464115746319\n",
      "<---------------------------------------------------->\n",
      "epoch: 53\n",
      "epoch train loss = 0.000746, epoch test loss = 0.055930, Time 00:00:11\n",
      "Acc = 0.853877, mIou = 0.424321\n",
      "epoch 54, 0/65,train loss is 0.00031922213383950293\n",
      "epoch 54, 15/65,train loss is 0.000942021724767983\n",
      "epoch 54, 30/65,train loss is 0.0007562272367067635\n",
      "epoch 54, 45/65,train loss is 0.0004810895770788193\n",
      "epoch 54, 60/65,train loss is 0.0009779904503375292\n",
      "<---------------------------------------------------->\n",
      "epoch: 54\n",
      "epoch train loss = 0.000706, epoch test loss = 0.052689, Time 00:00:11\n",
      "Acc = 0.926221, mIou = 0.594152\n",
      "saveing checkpoints/fcn_model_55.pth\n",
      "epoch 55, 0/65,train loss is 0.0006361809209920466\n",
      "epoch 55, 15/65,train loss is 0.0007284779567271471\n",
      "epoch 55, 30/65,train loss is 0.00046581923379562795\n",
      "epoch 55, 45/65,train loss is 0.0008098387625068426\n",
      "epoch 55, 60/65,train loss is 0.0006858080741949379\n",
      "<---------------------------------------------------->\n",
      "epoch: 55\n",
      "epoch train loss = 0.000724, epoch test loss = 0.052107, Time 00:00:11\n",
      "Acc = 0.871299, mIou = 0.461064\n",
      "epoch 56, 0/65,train loss is 0.0005903226556256413\n",
      "epoch 56, 15/65,train loss is 0.0005120394635014236\n",
      "epoch 56, 30/65,train loss is 0.000757636851631105\n",
      "epoch 56, 45/65,train loss is 0.0005279519828036427\n",
      "epoch 56, 60/65,train loss is 0.0009134662104770541\n",
      "<---------------------------------------------------->\n",
      "epoch: 56\n",
      "epoch train loss = 0.000698, epoch test loss = 0.050367, Time 00:00:11\n",
      "Acc = 0.933965, mIou = 0.610596\n",
      "epoch 57, 0/65,train loss is 0.0007101736846379936\n",
      "epoch 57, 15/65,train loss is 0.0008081626147031784\n",
      "epoch 57, 30/65,train loss is 0.0006337751401588321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57, 45/65,train loss is 0.000756728055421263\n",
      "epoch 57, 60/65,train loss is 0.0007063986267894506\n",
      "<---------------------------------------------------->\n",
      "epoch: 57\n",
      "epoch train loss = 0.000671, epoch test loss = 0.051568, Time 00:00:11\n",
      "Acc = 0.925146, mIou = 0.475744\n",
      "epoch 58, 0/65,train loss is 0.000657219672575593\n",
      "epoch 58, 15/65,train loss is 0.0005685832584276795\n",
      "epoch 58, 30/65,train loss is 0.0005612621316686273\n",
      "epoch 58, 45/65,train loss is 0.000606029643677175\n",
      "epoch 58, 60/65,train loss is 0.0004987397696822882\n",
      "<---------------------------------------------------->\n",
      "epoch: 58\n",
      "epoch train loss = 0.000618, epoch test loss = 0.052305, Time 00:00:11\n",
      "Acc = 0.921016, mIou = 0.528445\n",
      "epoch 59, 0/65,train loss is 0.0005275228759273887\n",
      "epoch 59, 15/65,train loss is 0.000446062273113057\n",
      "epoch 59, 30/65,train loss is 0.0003433804085943848\n",
      "epoch 59, 45/65,train loss is 0.0006851176731288433\n",
      "epoch 59, 60/65,train loss is 0.0006021327571943402\n",
      "<---------------------------------------------------->\n",
      "epoch: 59\n",
      "epoch train loss = 0.000568, epoch test loss = 0.049871, Time 00:00:11\n",
      "Acc = 0.962295, mIou = 0.603342\n",
      "saveing checkpoints/fcn_model_60.pth\n",
      "epoch 60, 0/65,train loss is 0.0004339168081060052\n",
      "epoch 60, 15/65,train loss is 0.0006690448499284685\n",
      "epoch 60, 30/65,train loss is 0.0009935898706316948\n",
      "epoch 60, 45/65,train loss is 0.0006354472716338933\n",
      "epoch 60, 60/65,train loss is 0.0005520384875126183\n",
      "<---------------------------------------------------->\n",
      "epoch: 60\n",
      "epoch train loss = 0.000599, epoch test loss = 0.055206, Time 00:00:11\n",
      "Acc = 0.890576, mIou = 0.427882\n",
      "epoch 61, 0/65,train loss is 0.0008019006345421076\n",
      "epoch 61, 15/65,train loss is 0.0004993336624465883\n",
      "epoch 61, 30/65,train loss is 0.0008834898471832275\n",
      "epoch 61, 45/65,train loss is 0.0005678336601704359\n",
      "epoch 61, 60/65,train loss is 0.0005966473836451769\n",
      "<---------------------------------------------------->\n",
      "epoch: 61\n",
      "epoch train loss = 0.000595, epoch test loss = 0.047077, Time 00:00:11\n",
      "Acc = 0.967334, mIou = 0.632660\n",
      "epoch 62, 0/65,train loss is 0.0006106824148446321\n",
      "epoch 62, 15/65,train loss is 0.0005665578064508736\n",
      "epoch 62, 30/65,train loss is 0.0005964211304672062\n",
      "epoch 62, 45/65,train loss is 0.0004055230529047549\n",
      "epoch 62, 60/65,train loss is 0.0005660517490468919\n",
      "<---------------------------------------------------->\n",
      "epoch: 62\n",
      "epoch train loss = 0.000532, epoch test loss = 0.057031, Time 00:00:11\n",
      "Acc = 0.886357, mIou = 0.462270\n",
      "epoch 63, 0/65,train loss is 0.0003611325810197741\n",
      "epoch 63, 15/65,train loss is 0.00044762788456864655\n",
      "epoch 63, 30/65,train loss is 0.0004659096885006875\n",
      "epoch 63, 45/65,train loss is 0.0006143677164800465\n",
      "epoch 63, 60/65,train loss is 0.0004936897894367576\n",
      "<---------------------------------------------------->\n",
      "epoch: 63\n",
      "epoch train loss = 0.000535, epoch test loss = 0.059799, Time 00:00:11\n",
      "Acc = 0.881084, mIou = 0.458526\n",
      "epoch 64, 0/65,train loss is 0.0007348418002948165\n",
      "epoch 64, 15/65,train loss is 0.000534111459273845\n",
      "epoch 64, 30/65,train loss is 0.000374652590835467\n",
      "epoch 64, 45/65,train loss is 0.0007418208988383412\n",
      "epoch 64, 60/65,train loss is 0.0005079758120700717\n",
      "<---------------------------------------------------->\n",
      "epoch: 64\n",
      "epoch train loss = 0.000560, epoch test loss = 0.052052, Time 00:00:11\n",
      "Acc = 0.923320, mIou = 0.576244\n",
      "saveing checkpoints/fcn_model_65.pth\n",
      "epoch 65, 0/65,train loss is 0.0003917331632692367\n",
      "epoch 65, 15/65,train loss is 0.0004148056323174387\n",
      "epoch 65, 30/65,train loss is 0.0004936891491524875\n",
      "epoch 65, 45/65,train loss is 0.00040934010758064687\n",
      "epoch 65, 60/65,train loss is 0.00048235556459985673\n",
      "<---------------------------------------------------->\n",
      "epoch: 65\n",
      "epoch train loss = 0.000526, epoch test loss = 0.051746, Time 00:00:11\n",
      "Acc = 0.935020, mIou = 0.747309\n",
      "epoch 66, 0/65,train loss is 0.0007148009608499706\n",
      "epoch 66, 15/65,train loss is 0.0004633511125575751\n",
      "epoch 66, 30/65,train loss is 0.00042607865179888904\n",
      "epoch 66, 45/65,train loss is 0.0005740800988860428\n",
      "epoch 66, 60/65,train loss is 0.0006396768731065094\n",
      "<---------------------------------------------------->\n",
      "epoch: 66\n",
      "epoch train loss = 0.000494, epoch test loss = 0.057870, Time 00:00:11\n",
      "Acc = 0.920488, mIou = 0.519332\n",
      "epoch 67, 0/65,train loss is 0.0004415460571181029\n",
      "epoch 67, 15/65,train loss is 0.0005402198294177651\n",
      "epoch 67, 30/65,train loss is 0.00042746178223751485\n",
      "epoch 67, 45/65,train loss is 0.0004692223446909338\n",
      "epoch 67, 60/65,train loss is 0.0005025728023611009\n",
      "<---------------------------------------------------->\n",
      "epoch: 67\n",
      "epoch train loss = 0.000461, epoch test loss = 0.051221, Time 00:00:11\n",
      "Acc = 0.984346, mIou = 0.797059\n",
      "epoch 68, 0/65,train loss is 0.0005204916815273464\n",
      "epoch 68, 15/65,train loss is 0.0003703304973896593\n",
      "epoch 68, 30/65,train loss is 0.0003337465168442577\n",
      "epoch 68, 45/65,train loss is 0.0006600097985938191\n",
      "epoch 68, 60/65,train loss is 0.0006876483676023781\n",
      "<---------------------------------------------------->\n",
      "epoch: 68\n",
      "epoch train loss = 0.000431, epoch test loss = 0.055714, Time 00:00:11\n",
      "Acc = 0.920166, mIou = 0.530504\n",
      "epoch 69, 0/65,train loss is 0.0003618126211222261\n",
      "epoch 69, 15/65,train loss is 0.00023252060054801404\n",
      "epoch 69, 30/65,train loss is 0.00047135166823863983\n",
      "epoch 69, 45/65,train loss is 0.0008608470670878887\n",
      "epoch 69, 60/65,train loss is 0.00045245300862006843\n",
      "<---------------------------------------------------->\n",
      "epoch: 69\n",
      "epoch train loss = 0.000448, epoch test loss = 0.058907, Time 00:00:11\n",
      "Acc = 0.922080, mIou = 0.508789\n",
      "saveing checkpoints/fcn_model_70.pth\n",
      "epoch 70, 0/65,train loss is 0.0005035618669353426\n",
      "epoch 70, 15/65,train loss is 0.00036254292353987694\n",
      "epoch 70, 30/65,train loss is 0.00036294202436693013\n",
      "epoch 70, 45/65,train loss is 0.0005320711061358452\n",
      "epoch 70, 60/65,train loss is 0.0005628259386867285\n",
      "<---------------------------------------------------->\n",
      "epoch: 70\n",
      "epoch train loss = 0.000441, epoch test loss = 0.060620, Time 00:00:11\n",
      "Acc = 0.899932, mIou = 0.452367\n",
      "epoch 71, 0/65,train loss is 0.0001890346029540524\n",
      "epoch 71, 15/65,train loss is 0.0005423664697445929\n",
      "epoch 71, 30/65,train loss is 0.0006024798494763672\n",
      "epoch 71, 45/65,train loss is 0.0005462929257191718\n",
      "epoch 71, 60/65,train loss is 0.0006090839742682874\n",
      "<---------------------------------------------------->\n",
      "epoch: 71\n",
      "epoch train loss = 0.000513, epoch test loss = 0.055204, Time 00:00:11\n",
      "Acc = 0.924063, mIou = 0.474021\n",
      "epoch 72, 0/65,train loss is 0.0004220162227284163\n",
      "epoch 72, 15/65,train loss is 0.00032089551677927375\n",
      "epoch 72, 30/65,train loss is 0.001434603938832879\n",
      "epoch 72, 45/65,train loss is 0.0007512423326261342\n",
      "epoch 72, 60/65,train loss is 0.0004120288067497313\n",
      "<---------------------------------------------------->\n",
      "epoch: 72\n",
      "epoch train loss = 0.000552, epoch test loss = 0.051297, Time 00:00:11\n",
      "Acc = 0.927725, mIou = 0.731304\n",
      "epoch 73, 0/65,train loss is 0.0002977512776851654\n",
      "epoch 73, 15/65,train loss is 0.0005135444225743413\n",
      "epoch 73, 30/65,train loss is 0.0007121724192984402\n",
      "epoch 73, 45/65,train loss is 0.000464010750874877\n",
      "epoch 73, 60/65,train loss is 0.0010321397567167878\n",
      "<---------------------------------------------------->\n",
      "epoch: 73\n",
      "epoch train loss = 0.000622, epoch test loss = 0.048259, Time 00:00:11\n",
      "Acc = 0.954570, mIou = 0.684572\n",
      "epoch 74, 0/65,train loss is 0.0006124198553152382\n",
      "epoch 74, 15/65,train loss is 0.0008204016485251486\n",
      "epoch 74, 30/65,train loss is 0.0007090151775628328\n",
      "epoch 74, 45/65,train loss is 0.0008273084531538188\n",
      "epoch 74, 60/65,train loss is 0.0007103919633664191\n",
      "<---------------------------------------------------->\n",
      "epoch: 74\n",
      "epoch train loss = 0.000760, epoch test loss = 0.050600, Time 00:00:11\n",
      "Acc = 0.913721, mIou = 0.480461\n",
      "saveing checkpoints/fcn_model_75.pth\n",
      "epoch 75, 0/65,train loss is 0.0003637775080278516\n",
      "epoch 75, 15/65,train loss is 0.0007347339414991438\n",
      "epoch 75, 30/65,train loss is 0.0005328571423888206\n",
      "epoch 75, 45/65,train loss is 0.0006615313468500972\n",
      "epoch 75, 60/65,train loss is 0.000422305689426139\n",
      "<---------------------------------------------------->\n",
      "epoch: 75\n",
      "epoch train loss = 0.000603, epoch test loss = 0.054953, Time 00:00:11\n",
      "Acc = 0.885898, mIou = 0.421669\n",
      "epoch 76, 0/65,train loss is 0.000492281629703939\n",
      "epoch 76, 15/65,train loss is 0.0003752656339202076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76, 30/65,train loss is 0.0004217289970256388\n",
      "epoch 76, 45/65,train loss is 0.0003213304153177887\n",
      "epoch 76, 60/65,train loss is 0.0004591531178448349\n",
      "<---------------------------------------------------->\n",
      "epoch: 76\n",
      "epoch train loss = 0.000472, epoch test loss = 0.052086, Time 00:00:11\n",
      "Acc = 0.966182, mIou = 0.731405\n",
      "epoch 77, 0/65,train loss is 0.00044049762072972953\n",
      "epoch 77, 15/65,train loss is 0.00038995122304186225\n",
      "epoch 77, 30/65,train loss is 0.0003334708162583411\n",
      "epoch 77, 45/65,train loss is 0.00035011928412131965\n",
      "epoch 77, 60/65,train loss is 0.0004329029470682144\n",
      "<---------------------------------------------------->\n",
      "epoch: 77\n",
      "epoch train loss = 0.000398, epoch test loss = 0.057700, Time 00:00:11\n",
      "Acc = 0.923945, mIou = 0.584697\n",
      "epoch 78, 0/65,train loss is 0.0002369596913922578\n",
      "epoch 78, 15/65,train loss is 0.0002981887955684215\n",
      "epoch 78, 30/65,train loss is 0.0004358626902103424\n",
      "epoch 78, 45/65,train loss is 0.00020451344607863575\n",
      "epoch 78, 60/65,train loss is 0.0003135143197141588\n",
      "<---------------------------------------------------->\n",
      "epoch: 78\n",
      "epoch train loss = 0.000356, epoch test loss = 0.060042, Time 00:00:11\n",
      "Acc = 0.926621, mIou = 0.527496\n",
      "epoch 79, 0/65,train loss is 0.0003371244529262185\n",
      "epoch 79, 15/65,train loss is 0.000293331773718819\n",
      "epoch 79, 30/65,train loss is 0.00046987374662421644\n",
      "epoch 79, 45/65,train loss is 0.00027458841213956475\n",
      "epoch 79, 60/65,train loss is 0.00032275833655148745\n",
      "<---------------------------------------------------->\n",
      "epoch: 79\n",
      "epoch train loss = 0.000386, epoch test loss = 0.056271, Time 00:00:11\n",
      "Acc = 0.932813, mIou = 0.639715\n",
      "saveing checkpoints/fcn_model_80.pth\n",
      "epoch 80, 0/65,train loss is 0.00046621603542007506\n",
      "epoch 80, 15/65,train loss is 0.00047756038838997483\n",
      "epoch 80, 30/65,train loss is 0.000370487425243482\n",
      "epoch 80, 45/65,train loss is 0.00048406055429950356\n",
      "epoch 80, 60/65,train loss is 0.0005678111920133233\n",
      "<---------------------------------------------------->\n",
      "epoch: 80\n",
      "epoch train loss = 0.000366, epoch test loss = 0.056118, Time 00:00:11\n",
      "Acc = 0.929941, mIou = 0.740803\n",
      "epoch 81, 0/65,train loss is 0.00037601578515022993\n",
      "epoch 81, 15/65,train loss is 0.00040255067870020866\n",
      "epoch 81, 30/65,train loss is 0.0005477624945342541\n",
      "epoch 81, 45/65,train loss is 0.000341367645887658\n",
      "epoch 81, 60/65,train loss is 0.000262868357822299\n",
      "<---------------------------------------------------->\n",
      "epoch: 81\n",
      "epoch train loss = 0.000400, epoch test loss = 0.053398, Time 00:00:11\n",
      "Acc = 0.959980, mIou = 0.599433\n",
      "epoch 82, 0/65,train loss is 0.00036097870906814933\n",
      "epoch 82, 15/65,train loss is 0.00021289211872499436\n",
      "epoch 82, 30/65,train loss is 0.000461417599581182\n",
      "epoch 82, 45/65,train loss is 0.0003103079507127404\n",
      "epoch 82, 60/65,train loss is 0.0002861649263650179\n",
      "<---------------------------------------------------->\n",
      "epoch: 82\n",
      "epoch train loss = 0.000346, epoch test loss = 0.056587, Time 00:00:11\n",
      "Acc = 0.945234, mIou = 0.576379\n",
      "epoch 83, 0/65,train loss is 0.00035090240999124944\n",
      "epoch 83, 15/65,train loss is 0.00023222299932967871\n",
      "epoch 83, 30/65,train loss is 0.00035477738128975034\n",
      "epoch 83, 45/65,train loss is 0.0004661103885155171\n",
      "epoch 83, 60/65,train loss is 0.0028293943032622337\n",
      "<---------------------------------------------------->\n",
      "epoch: 83\n",
      "epoch train loss = 0.000819, epoch test loss = 0.070037, Time 00:00:11\n",
      "Acc = 0.867158, mIou = 0.466307\n",
      "epoch 84, 0/65,train loss is 0.001761693973094225\n",
      "epoch 84, 15/65,train loss is 0.0028725725132972\n",
      "epoch 84, 30/65,train loss is 0.0013435942819342017\n",
      "epoch 84, 45/65,train loss is 0.0017735458677634597\n",
      "epoch 84, 60/65,train loss is 0.002107031410560012\n",
      "<---------------------------------------------------->\n",
      "epoch: 84\n",
      "epoch train loss = 0.002173, epoch test loss = 0.035359, Time 00:00:11\n",
      "Acc = 0.898770, mIou = 0.524056\n",
      "saveing checkpoints/fcn_model_85.pth\n",
      "epoch 85, 0/65,train loss is 0.0029502271208912134\n",
      "epoch 85, 15/65,train loss is 0.0012409449554979801\n",
      "epoch 85, 30/65,train loss is 0.004230163060128689\n",
      "epoch 85, 45/65,train loss is 0.0012340169632807374\n",
      "epoch 85, 60/65,train loss is 0.0014985932502895594\n",
      "<---------------------------------------------------->\n",
      "epoch: 85\n",
      "epoch train loss = 0.001564, epoch test loss = 0.037620, Time 00:00:11\n",
      "Acc = 0.900498, mIou = 0.469756\n",
      "epoch 86, 0/65,train loss is 0.000867463881149888\n",
      "epoch 86, 15/65,train loss is 0.0006326052243821323\n",
      "epoch 86, 30/65,train loss is 0.0007971863960847259\n",
      "epoch 86, 45/65,train loss is 0.0008022487163543701\n",
      "epoch 86, 60/65,train loss is 0.0006066067144274712\n",
      "<---------------------------------------------------->\n",
      "epoch: 86\n",
      "epoch train loss = 0.000892, epoch test loss = 0.039243, Time 00:00:11\n",
      "Acc = 0.984883, mIou = 0.821283\n",
      "epoch 87, 0/65,train loss is 0.0016399361193180084\n",
      "epoch 87, 15/65,train loss is 0.00047741486923769116\n",
      "epoch 87, 30/65,train loss is 0.00046486195060424507\n",
      "epoch 87, 45/65,train loss is 0.0005626057973131537\n",
      "epoch 87, 60/65,train loss is 0.0004731665540020913\n",
      "<---------------------------------------------------->\n",
      "epoch: 87\n",
      "epoch train loss = 0.000587, epoch test loss = 0.050188, Time 00:00:11\n",
      "Acc = 0.886914, mIou = 0.473968\n",
      "epoch 88, 0/65,train loss is 0.000505089177750051\n",
      "epoch 88, 15/65,train loss is 0.00030318094650283456\n",
      "epoch 88, 30/65,train loss is 0.0004859338514506817\n",
      "epoch 88, 45/65,train loss is 0.0002845863637048751\n",
      "epoch 88, 60/65,train loss is 0.0004505199904087931\n",
      "<---------------------------------------------------->\n",
      "epoch: 88\n",
      "epoch train loss = 0.000387, epoch test loss = 0.049992, Time 00:00:11\n",
      "Acc = 0.963896, mIou = 0.702083\n",
      "epoch 89, 0/65,train loss is 0.0003575784503482282\n",
      "epoch 89, 15/65,train loss is 0.0003049256338272244\n",
      "epoch 89, 30/65,train loss is 0.00020265310013201088\n",
      "epoch 89, 45/65,train loss is 0.00028458904125727713\n",
      "epoch 89, 60/65,train loss is 0.00026677059940993786\n",
      "<---------------------------------------------------->\n",
      "epoch: 89\n",
      "epoch train loss = 0.000295, epoch test loss = 0.055329, Time 00:00:11\n",
      "Acc = 0.923213, mIou = 0.713799\n",
      "saveing checkpoints/fcn_model_90.pth\n",
      "epoch 90, 0/65,train loss is 0.0002657950099091977\n",
      "epoch 90, 15/65,train loss is 0.00023512366169597954\n",
      "epoch 90, 30/65,train loss is 0.00033024713047780097\n",
      "epoch 90, 45/65,train loss is 0.0002338639897061512\n",
      "epoch 90, 60/65,train loss is 0.00039451479096896946\n",
      "<---------------------------------------------------->\n",
      "epoch: 90\n",
      "epoch train loss = 0.000248, epoch test loss = 0.061425, Time 00:00:11\n",
      "Acc = 0.888320, mIou = 0.475617\n",
      "epoch 91, 0/65,train loss is 0.00023412266455125064\n",
      "epoch 91, 15/65,train loss is 0.00017696067516226321\n",
      "epoch 91, 30/65,train loss is 0.0003285096609033644\n",
      "epoch 91, 45/65,train loss is 0.00017896613280754536\n",
      "epoch 91, 60/65,train loss is 0.0002535731764510274\n",
      "<---------------------------------------------------->\n",
      "epoch: 91\n",
      "epoch train loss = 0.000235, epoch test loss = 0.062516, Time 00:00:11\n",
      "Acc = 0.888916, mIou = 0.421236\n",
      "epoch 92, 0/65,train loss is 0.00017257840954698622\n",
      "epoch 92, 15/65,train loss is 0.0002707657986320555\n",
      "epoch 92, 30/65,train loss is 0.0003290936001576483\n",
      "epoch 92, 45/65,train loss is 0.00014989716873969883\n",
      "epoch 92, 60/65,train loss is 0.00026076097856275737\n",
      "<---------------------------------------------------->\n",
      "epoch: 92\n",
      "epoch train loss = 0.000228, epoch test loss = 0.058836, Time 00:00:11\n",
      "Acc = 0.919912, mIou = 0.534892\n",
      "epoch 93, 0/65,train loss is 0.00012239604257047176\n",
      "epoch 93, 15/65,train loss is 0.0001270655484404415\n",
      "epoch 93, 30/65,train loss is 0.00022806796187069267\n",
      "epoch 93, 45/65,train loss is 0.000283864006632939\n",
      "epoch 93, 60/65,train loss is 0.00017045873391907662\n",
      "<---------------------------------------------------->\n",
      "epoch: 93\n",
      "epoch train loss = 0.000216, epoch test loss = 0.058503, Time 00:00:11\n",
      "Acc = 0.964258, mIou = 0.703040\n",
      "epoch 94, 0/65,train loss is 0.00014439258666243404\n",
      "epoch 94, 15/65,train loss is 0.0002324359811609611\n",
      "epoch 94, 30/65,train loss is 0.00016542704543098807\n",
      "epoch 94, 45/65,train loss is 0.0001963040413102135\n",
      "epoch 94, 60/65,train loss is 0.0001632954372325912\n",
      "<---------------------------------------------------->\n",
      "epoch: 94\n",
      "epoch train loss = 0.000210, epoch test loss = 0.062470, Time 00:00:11\n",
      "Acc = 0.944756, mIou = 0.576960\n",
      "saveing checkpoints/fcn_model_95.pth\n",
      "epoch 95, 0/65,train loss is 0.00014479778474196792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95, 15/65,train loss is 0.00019872172561008483\n",
      "epoch 95, 30/65,train loss is 0.00018045786418952048\n",
      "epoch 95, 45/65,train loss is 0.0002917757083196193\n",
      "epoch 95, 60/65,train loss is 0.00015612183779012412\n",
      "<---------------------------------------------------->\n",
      "epoch: 95\n",
      "epoch train loss = 0.000214, epoch test loss = 0.064336, Time 00:00:11\n",
      "Acc = 0.923359, mIou = 0.575151\n",
      "epoch 96, 0/65,train loss is 0.00017357520118821412\n",
      "epoch 96, 15/65,train loss is 0.00021118161384947598\n",
      "epoch 96, 30/65,train loss is 0.00015705691475886852\n",
      "epoch 96, 45/65,train loss is 0.00030686770332977176\n",
      "epoch 96, 60/65,train loss is 0.00014202565944287926\n",
      "<---------------------------------------------------->\n",
      "epoch: 96\n",
      "epoch train loss = 0.000217, epoch test loss = 0.063832, Time 00:00:11\n",
      "Acc = 0.924395, mIou = 0.714628\n",
      "epoch 97, 0/65,train loss is 0.00024537634453736246\n",
      "epoch 97, 15/65,train loss is 0.00020726851653307676\n",
      "epoch 97, 30/65,train loss is 0.0002435722853988409\n",
      "epoch 97, 45/65,train loss is 0.00020969256001990288\n",
      "epoch 97, 60/65,train loss is 0.00023976428201422095\n",
      "<---------------------------------------------------->\n",
      "epoch: 97\n",
      "epoch train loss = 0.000212, epoch test loss = 0.061399, Time 00:00:11\n",
      "Acc = 0.945469, mIou = 0.566502\n",
      "epoch 98, 0/65,train loss is 0.00017920743266586214\n",
      "epoch 98, 15/65,train loss is 0.00018925029144156724\n",
      "epoch 98, 30/65,train loss is 0.00018092173559125513\n",
      "epoch 98, 45/65,train loss is 0.00026511226315051317\n",
      "epoch 98, 60/65,train loss is 0.00018700114742387086\n",
      "<---------------------------------------------------->\n",
      "epoch: 98\n",
      "epoch train loss = 0.000212, epoch test loss = 0.066380, Time 00:00:11\n",
      "Acc = 0.924346, mIou = 0.513629\n",
      "epoch 99, 0/65,train loss is 0.00021288637071847916\n",
      "epoch 99, 15/65,train loss is 0.0003033410175703466\n",
      "epoch 99, 30/65,train loss is 0.00024935041437856853\n",
      "epoch 99, 45/65,train loss is 0.0002467466110829264\n",
      "epoch 99, 60/65,train loss is 0.0002017924125539139\n",
      "<---------------------------------------------------->\n",
      "epoch: 99\n",
      "epoch train loss = 0.000213, epoch test loss = 0.067637, Time 00:00:11\n",
      "Acc = 0.919512, mIou = 0.570683\n",
      "saveing checkpoints/fcn_model_100.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "### 利用torchvision提供的transform，定义原始图片的预处理步骤（转换为tensor和标准化处理）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.35,0.35,0.35], std=[0.30, 0.30, 0.30])])\n",
    "# 实例化数据集\n",
    "road = BagDataset(transform)\n",
    "\n",
    "train_size = int(0.9 * len(road))\n",
    "test_size = len(road) - train_size\n",
    "train_dataset, test_dataset = random_split(road, [train_size, test_size])\n",
    "\n",
    "# 利用DataLoader生成一个分batch获取数据的可迭代对象\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "vgg_model = VGGNet(requires_grad=False,show_params=False)\n",
    "# # 仅采用FCN8s进行训练\n",
    "fcn_model = FCN8s(pretrained_net=vgg_model, n_class=3)\n",
    "train(fcn_model,epo_num=100,n_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.15.1-92d9ed92\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy_parallel('/home/ma-user/work/checkpoints/fcn_model_Focalloss_100.pth','obs://class-1275-42687/Lab-2210/modelarts22926584/fcn_model_Focalloss_100.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
