{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from Xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPPConv1x1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        ASPP用的5个处理之1，1个1x1卷积\n",
    "        :param in_channels: 输入channels，是backbone产生的主要特征的输出channels，这里是2048\n",
    "        :param out_channels: 输出channels，论文建议取值256\n",
    "        \"\"\"\n",
    "        super(ASPPConv1x1, self).__init__()\n",
    "        self.step = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.step(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPPConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dilation):\n",
    "        \"\"\"\n",
    "        ASPP用的5个处理之3，3个dilation conv，都是3x3的same卷积\n",
    "        :param in_channels: dilation conv的输入channels，是backbone产生的主要特征的输出channels，这里是2048\n",
    "        :param out_channels: dilation conv的输出channels，论文建议取值256\n",
    "        :param dilation: 膨胀率，论文建议取值6,12,18\n",
    "        \"\"\"\n",
    "        super(ASPPConv, self).__init__()\n",
    "        # same卷积padding=dilation*(k-1)/2\n",
    "        self.step = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                             padding=dilation, dilation=dilation, bias=False), \n",
    "                nn.BatchNorm2d(out_channels), \n",
    "                nn.ReLU()\n",
    "                )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.step(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPPPooling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        ASPP用的5个处理之1，Image Pooling\n",
    "        :param in_channels: 输入channels，是backbone产生的主要特征的输出channels，这里是2048\n",
    "        :param out_channels: 输出channels，论文建议取值256\n",
    "        \"\"\"\n",
    "        super(ASPPPooling, self).__init__()\n",
    "        # 全局平均池化，输出特征图大小1，再1x1卷积调整channels\n",
    "        self.step = nn.Sequential(nn.AdaptiveAvgPool2d(1),  \n",
    "                   nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False), \n",
    "                   nn.BatchNorm2d(out_channels), \n",
    "                   nn.ReLU()\n",
    "                   )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # 因为需要上采样，所以记录下输入的大小\n",
    "        size = x.shape[-2:]  \n",
    "        x = self.step(x)\n",
    "        # 双线性差值上采样到原特征图大小 \n",
    "        x = F.interpolate(x, size=size, mode='bilinear', align_corners=False)\n",
    "        return  x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASPP(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        ASPP，对backbone产生的主干特征进行空间金字塔池化。\n",
    "        金字塔有5层：1个1x1卷积，3个3x3 dilation conv，1个全局平均池化\n",
    "        将5层cat后再调整channels输出。\n",
    "        这里不进行upsample，因为不知道low-level的spatial大小。\n",
    "        :param in_channels: 输入channels，是backbone产生的主要特征的输出channels，这里是2048\n",
    "        :param out_channels: 输出channels，论文建议取值256\n",
    "        \"\"\"\n",
    "        super(ASPP, self).__init__()\n",
    "        modules = [ASPPConv1x1(in_channels, out_channels),  \n",
    "                   ASPPConv(in_channels, out_channels, dilation=6),\n",
    "                   ASPPConv(in_channels, out_channels, dilation=12), \n",
    "                   ASPPConv(in_channels, out_channels, dilation=18),\n",
    "                   ASPPPooling(in_channels, out_channels)] \n",
    "        self.convs = nn.ModuleList(modules)\n",
    "        # 一定要这样写，否则模型参数无法送入cuda\n",
    "        # 因为是并行计算，所以self.convs不能用nn.Sequential\n",
    "        # 金字塔池化后，输入channels为2048*5，输出channels还是256\n",
    "        self.project = nn.Sequential(nn.Conv2d(5 * out_channels, out_channels, 1, bias=False),\n",
    "                                     nn.BatchNorm2d(out_channels),\n",
    "                                     nn.ReLU())  \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = []\n",
    "        for mod in self.convs:\n",
    "            output.append(mod(x))\n",
    "        # 拼接各个计算结果，dim=1即channel方向上拼接\n",
    "        x = torch.cat(output, dim=1)\n",
    "        x = self.project(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabV3P(nn.Module):\n",
    "    # ASPP最终输出channels=256\n",
    "    aspp_out_channels = 256 \n",
    "    # 论文中说low-level特征减少channels到48 \n",
    "    reduce_to_channels = 48  \n",
    "\n",
    "    def __init__(self, in_channels, n_class):\n",
    "        super(DeepLabV3P, self).__init__()\n",
    "         # 取得backbone\n",
    "        self.backbone = Xception(in_channels) \n",
    "        # backbone的输出channels是2048，low_level的输出特征是128\n",
    "        aspp_in_channels, low_level_in_channels = 2048,128\n",
    "        # 金字塔池化\n",
    "        self.aspp = ASPP(aspp_in_channels, self.aspp_out_channels)  \n",
    "        # 将low_level的维度从128降低至47\n",
    "        self.reduce_channels = nn.Sequential(nn.Conv2d(low_level_in_channels, self.reduce_to_channels, 1, bias=False),\n",
    "                          nn.BatchNorm2d(self.reduce_to_channels),\n",
    "                          nn.ReLU())\n",
    "\n",
    "        # 高低特征融合后进行的操作，通道是高低特征通道的和，输出是256通道\n",
    "        # 两个3x3卷积\n",
    "        self.decode = nn.Sequential(nn.Conv2d(self.aspp_out_channels + self.reduce_to_channels,\n",
    "                                    self.aspp_out_channels,\n",
    "                                    3, padding=1, bias=False),\n",
    "                          nn.BatchNorm2d(self.aspp_out_channels),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Conv2d(self.aspp_out_channels,\n",
    "                                    self.aspp_out_channels,\n",
    "                                    3, padding=1, bias=False),\n",
    "                          nn.BatchNorm2d(self.aspp_out_channels),\n",
    "                          nn.ReLU())\n",
    "        # 最终分类，用1x1卷积降维，输出通道数为分类数目\n",
    "        self.classifier = nn.Conv2d(self.aspp_out_channels, n_class, 1)  \n",
    "\n",
    "        # 初始化参数\n",
    "        self._init_param()\n",
    "\n",
    "\n",
    "    def _init_param(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 记录图像原始大小\n",
    "        size1 = x.shape[-2:]  \n",
    "        # 提取特征，主干特征high-level和低级特征low-level\n",
    "        high_level, low_level = self.backbone(x)  \n",
    "        # low-leveld减少channels到48\n",
    "        low_level = self.reduce_channels(low_level)  \n",
    "        # 读取low-level特征图大小，即aspp上采样目标\n",
    "        size2 = low_level.shape[-2:]  \n",
    "\n",
    "        # 空间金字塔池化\n",
    "        high_level = self.aspp(high_level)  \n",
    "        # 上采样至和low-level的特征图大小一致\n",
    "        high_level = F.interpolate(high_level, size=size2, mode='bilinear',\n",
    "                                   align_corners=False)  \n",
    "\n",
    "        # cat融合一下\n",
    "        x = torch.cat([high_level, low_level], dim=1) \n",
    "        # 后面跟一系列3x3卷积，选择2个3x3卷积 \n",
    "        x = self.decode(x)\n",
    "        # 最终分类 \n",
    "        x = self.classifier(x)  \n",
    "        # 上采样和原图像大小一致\n",
    "        x = F.interpolate(x, size=size1, mode='bilinear', align_corners=False)\n",
    "        return  x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepLabV3P(\n",
      "  (backbone): Xception(\n",
      "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (block1): DownBlock(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
      "          (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (skip): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (block2): DownBlock(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (skip): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (block3): DownBlock(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (pointwise): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (skip): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (block4): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block5): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block6): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block7): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block8): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block9): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block10): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (block11): Block(\n",
      "      (sepconv1): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv2): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (sepconv3): SepConvBlock(\n",
      "        (relu): ReLU()\n",
      "        (sepconv): SeparableConv2d(\n",
      "          (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "          (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (sepconv12): SepConvBlock(\n",
      "      (relu): ReLU()\n",
      "      (sepconv): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sepconv13): SepConvBlock(\n",
      "      (relu): ReLU()\n",
      "      (sepconv): SeparableConv2d(\n",
      "        (conv1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
      "        (pointwise): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (sepconv14): SepConvBlock(\n",
      "      (relu): ReLU()\n",
      "      (sepconv): SeparableConv2d(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
      "        (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (skip15): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (conv16): SeparableConv2d(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
      "      (pointwise): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn16): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu16): ReLU()\n",
      "    (conv17): SeparableConv2d(\n",
      "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "      (pointwise): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn17): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu17): ReLU()\n",
      "    (conv18): SeparableConv2d(\n",
      "      (conv1): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
      "      (pointwise): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "    (bn18): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu18): ReLU()\n",
      "  )\n",
      "  (aspp): ASPP(\n",
      "    (convs): ModuleList(\n",
      "      (0): ASPPConv1x1(\n",
      "        (step): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (1): ASPPConv(\n",
      "        (step): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (2): ASPPConv(\n",
      "        (step): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (3): ASPPConv(\n",
      "        (step): Sequential(\n",
      "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "        )\n",
      "      )\n",
      "      (4): ASPPPooling(\n",
      "        (step): Sequential(\n",
      "          (0): AdaptiveAvgPool2d(output_size=1)\n",
      "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): ReLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (project): Sequential(\n",
      "      (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (reduce_channels): Sequential(\n",
      "    (0): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (decode): Sequential(\n",
      "    (0): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (classifier): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "in data: torch.Size([4, 3, 256, 768])\n",
      "out_data: torch.Size([4, 3, 256, 768])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "    net = DeepLabV3P(3, n_class=3).to(device)\n",
    "    print(net)\n",
    "\n",
    "    in_data = torch.randn((4, 3, 256, 768))\n",
    "    print('in data:', in_data.shape)\n",
    "    in_data = in_data.to(device)\n",
    "\n",
    "    out_data = net(in_data)\n",
    "    out_data = out_data.cpu()\n",
    "    print('out_data:', out_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用torch提供的Dataset类，定义我们自己的数据集\n",
    "import pandas as pd\n",
    "data = pd.read_csv('imgpath.csv')\n",
    "\n",
    "class BagDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = data.img_path[idx]\n",
    "        imgA = cv2.imread(img_name)\n",
    "        imgA = cv2.resize(imgA, (640, 160))\n",
    "        mask_name = data.mask_path[idx]\n",
    "        imgB = cv2.imread(mask_name, 0)\n",
    "        imgB = cv2.resize(imgB, (640, 160))\n",
    "        imgB[imgB==76] = 1\n",
    "        imgB[imgB>1] = 2\n",
    "        imgB = imgB.astype('uint8')\n",
    "        imgB = torch.FloatTensor(imgB)\n",
    "        # print(imgB.shape)\n",
    "        if self.transform:\n",
    "            imgA = self.transform(imgA)\n",
    "        return imgA, imgB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练网络前定义函数用于计算Acc 和 mIou\n",
    "# 计算混淆矩阵\n",
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    # mask把符合分类属性的位置取出来\n",
    "    # label_true和label_pred中最大值均为n_class-1，\n",
    "    # np.bincount统计各个数出现的次数，返回长度为序列最大值+1，\n",
    "    # minlength是返回的最大长度，小于最大值+1时无效，此处minlength = n_class**2，和混淆矩阵尺寸相同\n",
    "    # 返回一个n_class行n_class列的混淆矩阵，行是实际值，列是预测值\n",
    "    # hist计算中最大值为(n_class-1)*n_class+n_class，即n_class**2，以n_class=3为例\n",
    "    # 两者相加=0，实际为0，表示预测为0，\n",
    "    # 两者相加=1，实际为0，表示预测为1，\n",
    "    # 两者相加=2，实际为0，表示预测为2，\n",
    "    # 两者相加=3，实际为1，表示预测为0，\n",
    "    # 两者相加=4，实际为1，表示预测为1，\n",
    "    # 两者相加=5，实际为1，表示预测为2，\n",
    "    # 两者相加=6，实际为2，表示预测为0，\n",
    "    # 两者相加=7，实际为2，表示预测为1，\n",
    "    # 两者相加=8，实际为2，表示预测为2，\n",
    "    # np.bincount用于统计各个数值的个数，reshape后就是混淆矩阵\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据混淆矩阵计算Acc和mIou\n",
    "def label_accuracy_score(label_trues, label_preds, n_class):\n",
    "    # 生成混淆矩阵形状的矩阵\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    # 计算各个批次结果的混淆矩阵和\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    # np.diag把对角线的值取出来（即分类正确的个数）求和，并除以总数，即正确率\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    # 忽略错误的情况下，计算每一类的正确率\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    # 忽略nan的求平均\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    # axis=1表示按行求和，表示实际某类的个数，\n",
    "    # axis=0表示按列求和，表示预测某类的个数，\n",
    "    # 相加之后正好多加了一次对角线的数，因此减去对角线\n",
    "    # 相除之后表示某个类别预测正确的占正确的和错误的总和的比值\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        iu = np.diag(hist) / (\n",
    "                hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist)\n",
    "        )\n",
    "    # 忽略nan的求平均\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    return acc, acc_cls, mean_iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, class_num, alpha=0.25, gamma=2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        if alpha is None:\n",
    "            self.alpha = torch.ones(class_num, 1)\n",
    "        else:\n",
    "            self.alpha = torch.tensor(alpha, requires_grad=True)\n",
    "        self.gamma = gamma\n",
    "        self.class_num = class_num\n",
    "        self.size_average = size_average\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        # inputs.shape = (N,C,H,W)\n",
    "        N,C,H,W = inputs.shape\n",
    "        # 将inputs的形状变成N,H,W,C\n",
    "        inputs = inputs.permute([0,2,3,1])\n",
    "        # 第三维进行softmax\n",
    "        P = F.softmax(inputs,dim=3) \n",
    "        P = torch.clamp(P,0.0001,0.99)\n",
    "\n",
    "        # one hot start\n",
    "        # 生成和cross_entropy一样的shape形状,N,H,W,C\n",
    "        class_mask = inputs.data.new(N,H,W,self.class_num).fill_(0)  \n",
    "        # 需要更新，所以加入梯度计算\n",
    "        class_mask = class_mask.requires_grad_() \n",
    "        # 取得目标的索引，前三维要与class_mask一致\n",
    "        ids = targets.view(N,H,W,1) \n",
    "        # 利用scatter将ids的索引值将mask最后一个维度变成onehot，\n",
    "        class_mask.data.scatter_(3, ids.data, 1)\n",
    "        # one hot end\n",
    "\n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "\n",
    "        # 采用统一的alpha值\n",
    "        alpha = self.alpha\n",
    "        \n",
    "        probs = (P*class_mask).sum(3).view(N,H,W,1) \n",
    "        # 将softmax * one_hot格式，0的部分被消除，留下1的概率，即每个target的概率\n",
    "        \n",
    "        log_p = probs.log()\n",
    "        # 取得对数\n",
    "        \n",
    "        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p \n",
    "        # batch_loss就是取每一个batch的loss值\n",
    "        \n",
    "        \n",
    "        # 最终将每一个batch的loss加总后平均\n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(model,epo_num=50,n_class=3):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 定义交叉熵损失函数\n",
    "    criterion = FocalLoss(n_class).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # 记录训练过程相关指标\n",
    "    all_train_iter_loss = []\n",
    "    all_test_iter_loss = []\n",
    "    test_Acc = []\n",
    "    test_mIou = []\n",
    "    # 记录开始时间\n",
    "    prev_time = datetime.now()\n",
    "\n",
    "    for epo in range(epo_num):\n",
    "\n",
    "        # 训练\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for index, (road, road_msk) in enumerate(train_dataloader):\n",
    "            # road.shape = torch.Size([4, 3, 160, 640])\n",
    "            # road_msk.shape = torch.Size([4,160,640])\n",
    "\n",
    "            road = road.to(device)\n",
    "            road_msk = road_msk.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(road)\n",
    "\n",
    "\n",
    "            loss = criterion(output, road_msk.long())\n",
    "            loss.backward()  \n",
    "            # 需要计算导数，则调用backward\n",
    "            iter_loss = loss.item()  \n",
    "            # .item()返回一个具体的值，一般用于loss和acc\n",
    "            all_train_iter_loss.append(iter_loss)\n",
    "            train_loss += iter_loss\n",
    "            optimizer.step()\n",
    "\n",
    "            output_np = output.cpu().detach().numpy().copy()\n",
    "            output_np = np.argmax(output_np, axis=1)\n",
    "            road_msk_np = road_msk.cpu().detach().numpy().copy()\n",
    "\n",
    "            # 每15个bacth，输出一次训练过程的数据\n",
    "            if np.mod(index, 15) == 0:\n",
    "                print('epoch {}, {}/{},train loss is {}'.format(epo, index, len(train_dataloader), iter_loss))\n",
    "\n",
    "        # 验证\n",
    "        test_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for index, (road, road_msk) in enumerate(test_dataloader):\n",
    "                road = road.to(device)\n",
    "                road_msk = road_msk.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(road)\n",
    "                loss = criterion(output, road_msk.long())\n",
    "                iter_loss = loss.item()\n",
    "                all_test_iter_loss.append(iter_loss)\n",
    "                test_loss += iter_loss\n",
    "\n",
    "                # 把值小的那个位置取出来，即取出分类\n",
    "                output_np = output.cpu().detach().numpy().copy()\n",
    "                output_np = np.argmax(output_np, axis=1)\n",
    "                road_msk_np = road_msk.cpu().detach().numpy().copy()\n",
    "\n",
    "        cur_time = datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        prev_time = cur_time\n",
    "\n",
    "        print('<---------------------------------------------------->')\n",
    "        print('epoch: %d' % epo)\n",
    "        print('epoch train loss = %f, epoch test loss = %f, %s'\\\n",
    "              % (train_loss / len(train_dataloader), test_loss / len(test_dataloader), time_str))\n",
    "\n",
    "        acc, acc_cls, mean_iu = label_accuracy_score(road_msk_np, output_np, n_class)\n",
    "        test_Acc.append(acc)\n",
    "        test_mIou.append(mean_iu)\n",
    "\n",
    "        print('Acc = %f, mIou = %f' % (acc, mean_iu))\n",
    "        # 每5个epoch存储一次模型\n",
    "        if not os.path.exists('checkpoints'):\n",
    "            os.mkdir('checkpoints')\n",
    "        if np.mod(epo+1, 5) == 0:\n",
    "            # 只存储模型参数\n",
    "            torch.save(model.state_dict(), 'checkpoints/deeplabv3p_Focalloss_{}.pth'.format(epo+1))\n",
    "            print('saveing checkpoints/model_{}.pth'.format(epo+1))\n",
    "\n",
    "    # 绘制训练过程数据\n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title('train_loss')\n",
    "    plt.plot(all_train_iter_loss)\n",
    "    plt.xlabel('batch')\n",
    "    plt.subplot(222)\n",
    "    plt.title('test_loss')\n",
    "    plt.plot(all_test_iter_loss)\n",
    "    plt.xlabel('batch')\n",
    "    plt.subplot(223)\n",
    "    plt.title('test_Acc')\n",
    "    plt.plot(test_Acc)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.subplot(224)\n",
    "    plt.title('test_mIou')\n",
    "    plt.plot(test_mIou)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, 0/65,train loss is 0.6795916557312012\n",
      "epoch 0, 15/65,train loss is 0.3760790526866913\n",
      "epoch 0, 30/65,train loss is 0.130100280046463\n",
      "epoch 0, 45/65,train loss is 0.13425977528095245\n",
      "epoch 0, 60/65,train loss is 0.09208767861127853\n",
      "<---------------------------------------------------->\n",
      "epoch: 0\n",
      "epoch train loss = 0.204785, epoch test loss = 0.026102, Time 00:00:19\n",
      "Acc = 0.893555, mIou = 0.517680\n",
      "epoch 1, 0/65,train loss is 0.07343202084302902\n",
      "epoch 1, 15/65,train loss is 0.04520348832011223\n",
      "epoch 1, 30/65,train loss is 0.04575157165527344\n",
      "epoch 1, 45/65,train loss is 0.03326216712594032\n",
      "epoch 1, 60/65,train loss is 0.04575461149215698\n",
      "<---------------------------------------------------->\n",
      "epoch: 1\n",
      "epoch train loss = 0.043776, epoch test loss = 0.022723, Time 00:00:19\n",
      "Acc = 0.958789, mIou = 0.594125\n",
      "epoch 2, 0/65,train loss is 0.0276497732847929\n",
      "epoch 2, 15/65,train loss is 0.027483036741614342\n",
      "epoch 2, 30/65,train loss is 0.04241308942437172\n",
      "epoch 2, 45/65,train loss is 0.04971039667725563\n",
      "epoch 2, 60/65,train loss is 0.0158749520778656\n",
      "<---------------------------------------------------->\n",
      "epoch: 2\n",
      "epoch train loss = 0.033436, epoch test loss = 0.019375, Time 00:00:19\n",
      "Acc = 0.962861, mIou = 0.869846\n",
      "epoch 3, 0/65,train loss is 0.027083907276391983\n",
      "epoch 3, 15/65,train loss is 0.016805052757263184\n",
      "epoch 3, 30/65,train loss is 0.021843569353222847\n",
      "epoch 3, 45/65,train loss is 0.01748412847518921\n",
      "epoch 3, 60/65,train loss is 0.024762172251939774\n",
      "<---------------------------------------------------->\n",
      "epoch: 3\n",
      "epoch train loss = 0.022299, epoch test loss = 0.019855, Time 00:00:19\n",
      "Acc = 0.959922, mIou = 0.596829\n",
      "epoch 4, 0/65,train loss is 0.021690180525183678\n",
      "epoch 4, 15/65,train loss is 0.018185628578066826\n",
      "epoch 4, 30/65,train loss is 0.03005991131067276\n",
      "epoch 4, 45/65,train loss is 0.02503918670117855\n",
      "epoch 4, 60/65,train loss is 0.02098928578197956\n",
      "<---------------------------------------------------->\n",
      "epoch: 4\n",
      "epoch train loss = 0.021367, epoch test loss = 0.019218, Time 00:00:19\n",
      "Acc = 0.915850, mIou = 0.688364\n",
      "saveing checkpoints/model_5.pth\n",
      "epoch 5, 0/65,train loss is 0.01464205514639616\n",
      "epoch 5, 15/65,train loss is 0.027668418362736702\n",
      "epoch 5, 30/65,train loss is 0.014440168626606464\n",
      "epoch 5, 45/65,train loss is 0.014844843186438084\n",
      "epoch 5, 60/65,train loss is 0.014478943310678005\n",
      "<---------------------------------------------------->\n",
      "epoch: 5\n",
      "epoch train loss = 0.019639, epoch test loss = 0.029368, Time 00:00:19\n",
      "Acc = 0.889893, mIou = 0.441885\n",
      "epoch 6, 0/65,train loss is 0.013656003400683403\n",
      "epoch 6, 15/65,train loss is 0.018237411975860596\n",
      "epoch 6, 30/65,train loss is 0.022943444550037384\n",
      "epoch 6, 45/65,train loss is 0.012637736275792122\n",
      "epoch 6, 60/65,train loss is 0.016355952247977257\n",
      "<---------------------------------------------------->\n",
      "epoch: 6\n",
      "epoch train loss = 0.018360, epoch test loss = 0.026356, Time 00:00:19\n",
      "Acc = 0.938545, mIou = 0.557872\n",
      "epoch 7, 0/65,train loss is 0.0322817824780941\n",
      "epoch 7, 15/65,train loss is 0.016606302931904793\n",
      "epoch 7, 30/65,train loss is 0.016041971743106842\n",
      "epoch 7, 45/65,train loss is 0.019300634041428566\n",
      "epoch 7, 60/65,train loss is 0.013082413002848625\n",
      "<---------------------------------------------------->\n",
      "epoch: 7\n",
      "epoch train loss = 0.017492, epoch test loss = 0.016370, Time 00:00:19\n",
      "Acc = 0.900830, mIou = 0.450049\n",
      "epoch 8, 0/65,train loss is 0.020053638145327568\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-80b2ac7b3168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLabV3P\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepo_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-1996fc3987cb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epo_num, n_class)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroad_msk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# road.shape = torch.Size([4, 3, 160, 640])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# road_msk.shape = torch.Size([4,160,640])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-afbc6a415837>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimgA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mimgA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m160\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mmask_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mimgB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "### 利用torchvision提供的transform，定义原始图片的预处理步骤（转换为tensor和标准化处理）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.35,0.35,0.35], std=[0.30, 0.30, 0.30])])\n",
    "# 实例化数据集\n",
    "road = BagDataset(transform)\n",
    "\n",
    "train_size = int(0.9 * len(road))\n",
    "test_size = len(road) - train_size\n",
    "train_dataset, test_dataset = random_split(road, [train_size, test_size])\n",
    "\n",
    "# 利用DataLoader生成一个分batch获取数据的可迭代对象\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "model = DeepLabV3P(3,3)\n",
    "train(model,epo_num=100,n_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, 0/65,train loss is 0.004701993428170681\n",
      "epoch 0, 15/65,train loss is 0.013414930552244186\n",
      "epoch 0, 30/65,train loss is 0.014201571233570576\n",
      "epoch 0, 45/65,train loss is 0.014164912514388561\n",
      "epoch 0, 60/65,train loss is 0.02700878493487835\n",
      "<---------------------------------------------------->\n",
      "epoch: 0\n",
      "epoch train loss = 0.018414, epoch test loss = 0.147254, Time 00:00:19\n",
      "Acc = 0.915479, mIou = 0.457739\n",
      "epoch 1, 0/65,train loss is 0.0281929150223732\n",
      "epoch 1, 15/65,train loss is 0.023099178448319435\n",
      "epoch 1, 30/65,train loss is 0.018758367747068405\n",
      "epoch 1, 45/65,train loss is 0.017825592309236526\n",
      "epoch 1, 60/65,train loss is 0.012614247389137745\n",
      "<---------------------------------------------------->\n",
      "epoch: 1\n",
      "epoch train loss = 0.017244, epoch test loss = 0.361082, Time 00:00:19\n",
      "Acc = 0.772334, mIou = 0.386167\n",
      "epoch 2, 0/65,train loss is 0.013378077186644077\n",
      "epoch 2, 15/65,train loss is 0.015014683827757835\n",
      "epoch 2, 30/65,train loss is 0.017257751896977425\n",
      "epoch 2, 45/65,train loss is 0.011253537610173225\n",
      "epoch 2, 60/65,train loss is 0.01177100371569395\n",
      "<---------------------------------------------------->\n",
      "epoch: 2\n",
      "epoch train loss = 0.016864, epoch test loss = 0.013810, Time 00:00:19\n",
      "Acc = 0.920488, mIou = 0.475550\n",
      "epoch 3, 0/65,train loss is 0.01418119203299284\n",
      "epoch 3, 15/65,train loss is 0.010247733443975449\n",
      "epoch 3, 30/65,train loss is 0.02945193648338318\n",
      "epoch 3, 45/65,train loss is 0.014768712222576141\n",
      "epoch 3, 60/65,train loss is 0.026235321536660194\n",
      "<---------------------------------------------------->\n",
      "epoch: 3\n",
      "epoch train loss = 0.016424, epoch test loss = 0.014562, Time 00:00:19\n",
      "Acc = 0.922588, mIou = 0.530023\n",
      "epoch 4, 0/65,train loss is 0.013470525853335857\n",
      "epoch 4, 15/65,train loss is 0.012675129808485508\n",
      "epoch 4, 30/65,train loss is 0.019556019455194473\n",
      "epoch 4, 45/65,train loss is 0.01416713185608387\n",
      "epoch 4, 60/65,train loss is 0.01316800806671381\n",
      "<---------------------------------------------------->\n",
      "epoch: 4\n",
      "epoch train loss = 0.015688, epoch test loss = 0.105769, Time 00:00:19\n",
      "Acc = 0.871943, mIou = 0.443849\n",
      "saveing checkpoints/model_5.pth\n",
      "epoch 5, 0/65,train loss is 0.010613908991217613\n",
      "epoch 5, 15/65,train loss is 0.014019537717103958\n",
      "epoch 5, 30/65,train loss is 0.010207287967205048\n",
      "epoch 5, 45/65,train loss is 0.01147413719445467\n",
      "epoch 5, 60/65,train loss is 0.013080201111733913\n",
      "<---------------------------------------------------->\n",
      "epoch: 5\n",
      "epoch train loss = 0.015325, epoch test loss = 0.022499, Time 00:00:19\n",
      "Acc = 0.954141, mIou = 0.587853\n",
      "epoch 6, 0/65,train loss is 0.022943224757909775\n",
      "epoch 6, 15/65,train loss is 0.01768285222351551\n",
      "epoch 6, 30/65,train loss is 0.013918793760240078\n",
      "epoch 6, 45/65,train loss is 0.012339695356786251\n",
      "epoch 6, 60/65,train loss is 0.012059856206178665\n",
      "<---------------------------------------------------->\n",
      "epoch: 6\n",
      "epoch train loss = 0.014742, epoch test loss = 0.027701, Time 00:00:19\n",
      "Acc = 0.953457, mIou = 0.589422\n",
      "epoch 7, 0/65,train loss is 0.018287083134055138\n",
      "epoch 7, 15/65,train loss is 0.013497860170900822\n",
      "epoch 7, 30/65,train loss is 0.012419200502336025\n",
      "epoch 7, 45/65,train loss is 0.017678629606962204\n",
      "epoch 7, 60/65,train loss is 0.011886052787303925\n",
      "<---------------------------------------------------->\n",
      "epoch: 7\n",
      "epoch train loss = 0.014486, epoch test loss = 0.014829, Time 00:00:19\n",
      "Acc = 0.884775, mIou = 0.496266\n",
      "epoch 8, 0/65,train loss is 0.025563115254044533\n",
      "epoch 8, 15/65,train loss is 0.01481704693287611\n",
      "epoch 8, 30/65,train loss is 0.012653736397624016\n",
      "epoch 8, 45/65,train loss is 0.011274321936070919\n",
      "epoch 8, 60/65,train loss is 0.011343910358846188\n",
      "<---------------------------------------------------->\n",
      "epoch: 8\n",
      "epoch train loss = 0.014311, epoch test loss = 0.107537, Time 00:00:19\n",
      "Acc = 0.876904, mIou = 0.400490\n",
      "epoch 9, 0/65,train loss is 0.014020588248968124\n",
      "epoch 9, 15/65,train loss is 0.016360441222786903\n",
      "epoch 9, 30/65,train loss is 0.011649459600448608\n",
      "epoch 9, 45/65,train loss is 0.011273098178207874\n",
      "epoch 9, 60/65,train loss is 0.038602571934461594\n",
      "<---------------------------------------------------->\n",
      "epoch: 9\n",
      "epoch train loss = 0.014432, epoch test loss = 0.301975, Time 00:00:19\n",
      "Acc = 0.884121, mIou = 0.485458\n",
      "saveing checkpoints/model_10.pth\n",
      "epoch 10, 0/65,train loss is 0.009268375113606453\n",
      "epoch 10, 15/65,train loss is 0.010960549116134644\n",
      "epoch 10, 30/65,train loss is 0.015084597282111645\n",
      "epoch 10, 45/65,train loss is 0.011808293871581554\n",
      "epoch 10, 60/65,train loss is 0.009384232573211193\n",
      "<---------------------------------------------------->\n",
      "epoch: 10\n",
      "epoch train loss = 0.014496, epoch test loss = 0.090143, Time 00:00:19\n",
      "Acc = 0.936514, mIou = 0.581712\n",
      "epoch 11, 0/65,train loss is 0.012119208462536335\n",
      "epoch 11, 15/65,train loss is 0.010785111226141453\n",
      "epoch 11, 30/65,train loss is 0.008458754047751427\n",
      "epoch 11, 45/65,train loss is 0.009040036238729954\n",
      "epoch 11, 60/65,train loss is 0.02387697622179985\n",
      "<---------------------------------------------------->\n",
      "epoch: 11\n",
      "epoch train loss = 0.013691, epoch test loss = 0.014370, Time 00:00:19\n",
      "Acc = 0.882314, mIou = 0.506271\n",
      "epoch 12, 0/65,train loss is 0.011077497154474258\n",
      "epoch 12, 15/65,train loss is 0.015983600169420242\n",
      "epoch 12, 30/65,train loss is 0.014495125971734524\n",
      "epoch 12, 45/65,train loss is 0.03401407599449158\n",
      "epoch 12, 60/65,train loss is 0.012378957122564316\n",
      "<---------------------------------------------------->\n",
      "epoch: 12\n",
      "epoch train loss = 0.014177, epoch test loss = 0.013552, Time 00:00:19\n",
      "Acc = 0.906328, mIou = 0.427645\n",
      "epoch 13, 0/65,train loss is 0.011467414908111095\n",
      "epoch 13, 15/65,train loss is 0.015344483777880669\n",
      "epoch 13, 30/65,train loss is 0.010638288222253323\n",
      "epoch 13, 45/65,train loss is 0.012527994811534882\n",
      "epoch 13, 60/65,train loss is 0.01840232126414776\n",
      "<---------------------------------------------------->\n",
      "epoch: 13\n",
      "epoch train loss = 0.013833, epoch test loss = 0.043874, Time 00:00:19\n",
      "Acc = 0.931572, mIou = 0.555016\n",
      "epoch 14, 0/65,train loss is 0.015605430118739605\n",
      "epoch 14, 15/65,train loss is 0.014380893670022488\n",
      "epoch 14, 30/65,train loss is 0.018045539036393166\n",
      "epoch 14, 45/65,train loss is 0.021944165229797363\n",
      "epoch 14, 60/65,train loss is 0.01053636334836483\n",
      "<---------------------------------------------------->\n",
      "epoch: 14\n",
      "epoch train loss = 0.013759, epoch test loss = 0.013179, Time 00:00:19\n",
      "Acc = 0.910889, mIou = 0.739472\n",
      "saveing checkpoints/model_15.pth\n",
      "epoch 15, 0/65,train loss is 0.008147437125444412\n",
      "epoch 15, 15/65,train loss is 0.014588859863579273\n",
      "epoch 15, 30/65,train loss is 0.01740289479494095\n",
      "epoch 15, 45/65,train loss is 0.011320248246192932\n",
      "epoch 15, 60/65,train loss is 0.012108664028346539\n",
      "<---------------------------------------------------->\n",
      "epoch: 15\n",
      "epoch train loss = 0.013208, epoch test loss = 0.013151, Time 00:00:19\n",
      "Acc = 0.934736, mIou = 0.497105\n",
      "epoch 16, 0/65,train loss is 0.007926125079393387\n",
      "epoch 16, 15/65,train loss is 0.009522325359284878\n",
      "epoch 16, 30/65,train loss is 0.009916136972606182\n",
      "epoch 16, 45/65,train loss is 0.010816969908773899\n",
      "epoch 16, 60/65,train loss is 0.014951365068554878\n",
      "<---------------------------------------------------->\n",
      "epoch: 16\n",
      "epoch train loss = 0.013064, epoch test loss = 0.013542, Time 00:00:19\n",
      "Acc = 0.952588, mIou = 0.559460\n",
      "epoch 17, 0/65,train loss is 0.011273988522589207\n",
      "epoch 17, 15/65,train loss is 0.008670639246702194\n",
      "epoch 17, 30/65,train loss is 0.009730979800224304\n",
      "epoch 17, 45/65,train loss is 0.012813935056328773\n",
      "epoch 17, 60/65,train loss is 0.0128098139539361\n",
      "<---------------------------------------------------->\n",
      "epoch: 17\n",
      "epoch train loss = 0.012737, epoch test loss = 0.158073, Time 00:00:19\n",
      "Acc = 0.752803, mIou = 0.251064\n",
      "epoch 18, 0/65,train loss is 0.008710146881639957\n",
      "epoch 18, 15/65,train loss is 0.011885670945048332\n",
      "epoch 18, 30/65,train loss is 0.021385574713349342\n",
      "epoch 18, 45/65,train loss is 0.012220396660268307\n",
      "epoch 18, 60/65,train loss is 0.02077842503786087\n",
      "<---------------------------------------------------->\n",
      "epoch: 18\n",
      "epoch train loss = 0.013175, epoch test loss = 0.014755, Time 00:00:19\n",
      "Acc = 0.931895, mIou = 0.578625\n",
      "epoch 19, 0/65,train loss is 0.01952873356640339\n",
      "epoch 19, 15/65,train loss is 0.010237506590783596\n",
      "epoch 19, 30/65,train loss is 0.01360971387475729\n",
      "epoch 19, 45/65,train loss is 0.008575982414186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, 60/65,train loss is 0.018777139484882355\n",
      "<---------------------------------------------------->\n",
      "epoch: 19\n",
      "epoch train loss = 0.012826, epoch test loss = 0.013348, Time 00:00:19\n",
      "Acc = 0.944951, mIou = 0.516178\n",
      "saveing checkpoints/model_20.pth\n",
      "epoch 20, 0/65,train loss is 0.013155956752598286\n",
      "epoch 20, 15/65,train loss is 0.018253812566399574\n",
      "epoch 20, 30/65,train loss is 0.00988569762557745\n",
      "epoch 20, 45/65,train loss is 0.01192246749997139\n",
      "epoch 20, 60/65,train loss is 0.008269594982266426\n",
      "<---------------------------------------------------->\n",
      "epoch: 20\n",
      "epoch train loss = 0.012393, epoch test loss = 0.012076, Time 00:00:19\n",
      "Acc = 0.987920, mIou = 0.664729\n",
      "epoch 21, 0/65,train loss is 0.01462539378553629\n",
      "epoch 21, 15/65,train loss is 0.012383755296468735\n",
      "epoch 21, 30/65,train loss is 0.011145521886646748\n",
      "epoch 21, 45/65,train loss is 0.01408508513122797\n",
      "epoch 21, 60/65,train loss is 0.017252637073397636\n",
      "<---------------------------------------------------->\n",
      "epoch: 21\n",
      "epoch train loss = 0.012583, epoch test loss = 0.014389, Time 00:00:19\n",
      "Acc = 0.910391, mIou = 0.533981\n",
      "epoch 22, 0/65,train loss is 0.015112045221030712\n",
      "epoch 22, 15/65,train loss is 0.013798554427921772\n",
      "epoch 22, 30/65,train loss is 0.013394948095083237\n",
      "epoch 22, 45/65,train loss is 0.01223877165466547\n",
      "epoch 22, 60/65,train loss is 0.012957246974110603\n",
      "<---------------------------------------------------->\n",
      "epoch: 22\n",
      "epoch train loss = 0.012216, epoch test loss = 0.013004, Time 00:00:19\n",
      "Acc = 0.973916, mIou = 0.622420\n",
      "epoch 23, 0/65,train loss is 0.02169656753540039\n",
      "epoch 23, 15/65,train loss is 0.009927323088049889\n",
      "epoch 23, 30/65,train loss is 0.009250289760529995\n",
      "epoch 23, 45/65,train loss is 0.021604761481285095\n",
      "epoch 23, 60/65,train loss is 0.016428980976343155\n",
      "<---------------------------------------------------->\n",
      "epoch: 23\n",
      "epoch train loss = 0.011755, epoch test loss = 0.013250, Time 00:00:19\n",
      "Acc = 0.921299, mIou = 0.550855\n",
      "epoch 24, 0/65,train loss is 0.018566718325018883\n",
      "epoch 24, 15/65,train loss is 0.011262306943535805\n",
      "epoch 24, 30/65,train loss is 0.008157512173056602\n",
      "epoch 24, 45/65,train loss is 0.011622707359492779\n",
      "epoch 24, 60/65,train loss is 0.01310416404157877\n",
      "<---------------------------------------------------->\n",
      "epoch: 24\n",
      "epoch train loss = 0.011444, epoch test loss = 0.013301, Time 00:00:19\n",
      "Acc = 0.961650, mIou = 0.675529\n",
      "saveing checkpoints/model_25.pth\n",
      "epoch 25, 0/65,train loss is 0.0141372699290514\n",
      "epoch 25, 15/65,train loss is 0.0069990335032343864\n",
      "epoch 25, 30/65,train loss is 0.018179545179009438\n",
      "epoch 25, 45/65,train loss is 0.00825415924191475\n",
      "epoch 25, 60/65,train loss is 0.008030460216104984\n",
      "<---------------------------------------------------->\n",
      "epoch: 25\n",
      "epoch train loss = 0.011627, epoch test loss = 0.014781, Time 00:00:19\n",
      "Acc = 0.885537, mIou = 0.510788\n",
      "epoch 26, 0/65,train loss is 0.008399142883718014\n",
      "epoch 26, 15/65,train loss is 0.011164648458361626\n",
      "epoch 26, 30/65,train loss is 0.013702326454222202\n",
      "epoch 26, 45/65,train loss is 0.006737923249602318\n",
      "epoch 26, 60/65,train loss is 0.016810040920972824\n",
      "<---------------------------------------------------->\n",
      "epoch: 26\n",
      "epoch train loss = 0.011067, epoch test loss = 0.012814, Time 00:00:19\n",
      "Acc = 0.968408, mIou = 0.797803\n",
      "epoch 27, 0/65,train loss is 0.011535744182765484\n",
      "epoch 27, 15/65,train loss is 0.013087751343846321\n",
      "epoch 27, 30/65,train loss is 0.011140832677483559\n",
      "epoch 27, 45/65,train loss is 0.020352473482489586\n",
      "epoch 27, 60/65,train loss is 0.011238289065659046\n",
      "<---------------------------------------------------->\n",
      "epoch: 27\n",
      "epoch train loss = 0.011446, epoch test loss = 0.015378, Time 00:00:19\n",
      "Acc = 0.933262, mIou = 0.594383\n",
      "epoch 28, 0/65,train loss is 0.016379401087760925\n",
      "epoch 28, 15/65,train loss is 0.0068749007768929005\n",
      "epoch 28, 30/65,train loss is 0.014304975979030132\n",
      "epoch 28, 45/65,train loss is 0.010906887240707874\n",
      "epoch 28, 60/65,train loss is 0.008112415671348572\n",
      "<---------------------------------------------------->\n",
      "epoch: 28\n",
      "epoch train loss = 0.011276, epoch test loss = 0.014675, Time 00:00:19\n",
      "Acc = 0.915391, mIou = 0.514237\n",
      "epoch 29, 0/65,train loss is 0.01018352247774601\n",
      "epoch 29, 15/65,train loss is 0.009693780913949013\n",
      "epoch 29, 30/65,train loss is 0.009757484309375286\n",
      "epoch 29, 45/65,train loss is 0.012241922318935394\n",
      "epoch 29, 60/65,train loss is 0.007858972996473312\n",
      "<---------------------------------------------------->\n",
      "epoch: 29\n",
      "epoch train loss = 0.010804, epoch test loss = 0.016036, Time 00:00:19\n",
      "Acc = 0.923574, mIou = 0.562882\n",
      "saveing checkpoints/model_30.pth\n",
      "epoch 30, 0/65,train loss is 0.011105160228908062\n",
      "epoch 30, 15/65,train loss is 0.009434079751372337\n",
      "epoch 30, 30/65,train loss is 0.014073271304368973\n",
      "epoch 30, 45/65,train loss is 0.010578470304608345\n",
      "epoch 30, 60/65,train loss is 0.01037877518683672\n",
      "<---------------------------------------------------->\n",
      "epoch: 30\n",
      "epoch train loss = 0.010946, epoch test loss = 0.012109, Time 00:00:19\n",
      "Acc = 0.971943, mIou = 0.598195\n",
      "epoch 31, 0/65,train loss is 0.007823710329830647\n",
      "epoch 31, 15/65,train loss is 0.009170876815915108\n",
      "epoch 31, 30/65,train loss is 0.007778126280754805\n",
      "epoch 31, 45/65,train loss is 0.012345745228230953\n",
      "epoch 31, 60/65,train loss is 0.008458497002720833\n",
      "<---------------------------------------------------->\n",
      "epoch: 31\n",
      "epoch train loss = 0.010551, epoch test loss = 0.014410, Time 00:00:19\n",
      "Acc = 0.945693, mIou = 0.550339\n",
      "epoch 32, 0/65,train loss is 0.010086157359182835\n",
      "epoch 32, 15/65,train loss is 0.008891038596630096\n",
      "epoch 32, 30/65,train loss is 0.007354397792369127\n",
      "epoch 32, 45/65,train loss is 0.00928157102316618\n",
      "epoch 32, 60/65,train loss is 0.016527077183127403\n",
      "<---------------------------------------------------->\n",
      "epoch: 32\n",
      "epoch train loss = 0.010692, epoch test loss = 0.014235, Time 00:00:19\n",
      "Acc = 0.919609, mIou = 0.549784\n",
      "epoch 33, 0/65,train loss is 0.011835891753435135\n",
      "epoch 33, 15/65,train loss is 0.008736804127693176\n",
      "epoch 33, 30/65,train loss is 0.012297630310058594\n",
      "epoch 33, 45/65,train loss is 0.008582315407693386\n",
      "epoch 33, 60/65,train loss is 0.013411366380751133\n",
      "<---------------------------------------------------->\n",
      "epoch: 33\n",
      "epoch train loss = 0.010184, epoch test loss = 0.013314, Time 00:00:19\n",
      "Acc = 0.946172, mIou = 0.545099\n",
      "epoch 34, 0/65,train loss is 0.011133480817079544\n",
      "epoch 34, 15/65,train loss is 0.009039354510605335\n",
      "epoch 34, 30/65,train loss is 0.0075852274894714355\n",
      "epoch 34, 45/65,train loss is 0.008241500705480576\n",
      "epoch 34, 60/65,train loss is 0.009449142031371593\n",
      "<---------------------------------------------------->\n",
      "epoch: 34\n",
      "epoch train loss = 0.010055, epoch test loss = 0.012788, Time 00:00:19\n",
      "Acc = 0.967275, mIou = 0.907512\n",
      "saveing checkpoints/model_35.pth\n",
      "epoch 35, 0/65,train loss is 0.009324699640274048\n",
      "epoch 35, 15/65,train loss is 0.007897547446191311\n",
      "epoch 35, 30/65,train loss is 0.009071318432688713\n",
      "epoch 35, 45/65,train loss is 0.012959594838321209\n",
      "epoch 35, 60/65,train loss is 0.010471299290657043\n",
      "<---------------------------------------------------->\n",
      "epoch: 35\n",
      "epoch train loss = 0.009602, epoch test loss = 0.015454, Time 00:00:19\n",
      "Acc = 0.913730, mIou = 0.518638\n",
      "epoch 36, 0/65,train loss is 0.009460870176553726\n",
      "epoch 36, 15/65,train loss is 0.008083179593086243\n",
      "epoch 36, 30/65,train loss is 0.01347725372761488\n",
      "epoch 36, 45/65,train loss is 0.017524918541312218\n",
      "epoch 36, 60/65,train loss is 0.00878455862402916\n",
      "<---------------------------------------------------->\n",
      "epoch: 36\n",
      "epoch train loss = 0.010208, epoch test loss = 0.019731, Time 00:00:19\n",
      "Acc = 0.906074, mIou = 0.589500\n",
      "epoch 37, 0/65,train loss is 0.009738747030496597\n",
      "epoch 37, 15/65,train loss is 0.007441365625709295\n",
      "epoch 37, 30/65,train loss is 0.00947156734764576\n",
      "epoch 37, 45/65,train loss is 0.0074338181875646114\n",
      "epoch 37, 60/65,train loss is 0.015385190024971962\n",
      "<---------------------------------------------------->\n",
      "epoch: 37\n",
      "epoch train loss = 0.009711, epoch test loss = 0.013344, Time 00:00:19\n",
      "Acc = 0.959023, mIou = 0.542259\n",
      "epoch 38, 0/65,train loss is 0.00879589095711708\n",
      "epoch 38, 15/65,train loss is 0.0077523826621472836\n",
      "epoch 38, 30/65,train loss is 0.007221727166324854\n",
      "epoch 38, 45/65,train loss is 0.010592073202133179\n",
      "epoch 38, 60/65,train loss is 0.007868639193475246\n",
      "<---------------------------------------------------->\n",
      "epoch: 38\n",
      "epoch train loss = 0.009587, epoch test loss = 0.013178, Time 00:00:19\n",
      "Acc = 0.961348, mIou = 0.811037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, 0/65,train loss is 0.0075852456502616405\n",
      "epoch 39, 15/65,train loss is 0.010771634057164192\n",
      "epoch 39, 30/65,train loss is 0.019552836194634438\n",
      "epoch 39, 45/65,train loss is 0.013654866255819798\n",
      "epoch 39, 60/65,train loss is 0.008165528997778893\n",
      "<---------------------------------------------------->\n",
      "epoch: 39\n",
      "epoch train loss = 0.009414, epoch test loss = 0.019688, Time 00:00:19\n",
      "Acc = 0.964688, mIou = 0.606492\n",
      "saveing checkpoints/model_40.pth\n",
      "epoch 40, 0/65,train loss is 0.008472182787954807\n",
      "epoch 40, 15/65,train loss is 0.008193728514015675\n",
      "epoch 40, 30/65,train loss is 0.01014756504446268\n",
      "epoch 40, 45/65,train loss is 0.00867672823369503\n",
      "epoch 40, 60/65,train loss is 0.0075833760201931\n",
      "<---------------------------------------------------->\n",
      "epoch: 40\n",
      "epoch train loss = 0.008839, epoch test loss = 0.014480, Time 00:00:19\n",
      "Acc = 0.926670, mIou = 0.551907\n",
      "epoch 41, 0/65,train loss is 0.00823920127004385\n",
      "epoch 41, 15/65,train loss is 0.007058143615722656\n",
      "epoch 41, 30/65,train loss is 0.009768196381628513\n",
      "epoch 41, 45/65,train loss is 0.010731651447713375\n",
      "epoch 41, 60/65,train loss is 0.009095788933336735\n",
      "<---------------------------------------------------->\n",
      "epoch: 41\n",
      "epoch train loss = 0.009006, epoch test loss = 0.018967, Time 00:00:19\n",
      "Acc = 0.940742, mIou = 0.559441\n",
      "epoch 42, 0/65,train loss is 0.005332034546881914\n",
      "epoch 42, 15/65,train loss is 0.007536408957093954\n",
      "epoch 42, 30/65,train loss is 0.007291301153600216\n",
      "epoch 42, 45/65,train loss is 0.006188231520354748\n",
      "epoch 42, 60/65,train loss is 0.008161625824868679\n",
      "<---------------------------------------------------->\n",
      "epoch: 42\n",
      "epoch train loss = 0.008510, epoch test loss = 0.015318, Time 00:00:19\n",
      "Acc = 0.917041, mIou = 0.503604\n",
      "epoch 43, 0/65,train loss is 0.009864004328846931\n",
      "epoch 43, 15/65,train loss is 0.007116649765521288\n",
      "epoch 43, 30/65,train loss is 0.006816507317125797\n",
      "epoch 43, 45/65,train loss is 0.013325567357242107\n",
      "epoch 43, 60/65,train loss is 0.011906919069588184\n",
      "<---------------------------------------------------->\n",
      "epoch: 43\n",
      "epoch train loss = 0.009702, epoch test loss = 0.013971, Time 00:00:19\n",
      "Acc = 0.937578, mIou = 0.741850\n",
      "epoch 44, 0/65,train loss is 0.007367175072431564\n",
      "epoch 44, 15/65,train loss is 0.01312737911939621\n",
      "epoch 44, 30/65,train loss is 0.007968312129378319\n",
      "epoch 44, 45/65,train loss is 0.007548745255917311\n",
      "epoch 44, 60/65,train loss is 0.010946833528578281\n",
      "<---------------------------------------------------->\n",
      "epoch: 44\n",
      "epoch train loss = 0.009830, epoch test loss = 0.013692, Time 00:00:19\n",
      "Acc = 0.872275, mIou = 0.474769\n",
      "saveing checkpoints/model_45.pth\n",
      "epoch 45, 0/65,train loss is 0.0064834849908947945\n",
      "epoch 45, 15/65,train loss is 0.009991473518311977\n",
      "epoch 45, 30/65,train loss is 0.00898661557585001\n",
      "epoch 45, 45/65,train loss is 0.0090009281411767\n",
      "epoch 45, 60/65,train loss is 0.010639725252985954\n",
      "<---------------------------------------------------->\n",
      "epoch: 45\n",
      "epoch train loss = 0.008884, epoch test loss = 0.014167, Time 00:00:19\n",
      "Acc = 0.933594, mIou = 0.576725\n",
      "epoch 46, 0/65,train loss is 0.0067728678695857525\n",
      "epoch 46, 15/65,train loss is 0.006974139250814915\n",
      "epoch 46, 30/65,train loss is 0.0033312994055449963\n",
      "epoch 46, 45/65,train loss is 0.009441379457712173\n",
      "epoch 46, 60/65,train loss is 0.007188886404037476\n",
      "<---------------------------------------------------->\n",
      "epoch: 46\n",
      "epoch train loss = 0.007947, epoch test loss = 0.014261, Time 00:00:19\n",
      "Acc = 0.921602, mIou = 0.526931\n",
      "epoch 47, 0/65,train loss is 0.0070614563301205635\n",
      "epoch 47, 15/65,train loss is 0.0098069217056036\n",
      "epoch 47, 30/65,train loss is 0.01139601320028305\n",
      "epoch 47, 45/65,train loss is 0.008047008886933327\n",
      "epoch 47, 60/65,train loss is 0.008012286387383938\n",
      "<---------------------------------------------------->\n",
      "epoch: 47\n",
      "epoch train loss = 0.008042, epoch test loss = 0.014360, Time 00:00:19\n",
      "Acc = 0.865830, mIou = 0.498719\n",
      "epoch 48, 0/65,train loss is 0.007605863269418478\n",
      "epoch 48, 15/65,train loss is 0.007185974158346653\n",
      "epoch 48, 30/65,train loss is 0.010269745253026485\n",
      "epoch 48, 45/65,train loss is 0.006088130176067352\n",
      "epoch 48, 60/65,train loss is 0.011317223310470581\n",
      "<---------------------------------------------------->\n",
      "epoch: 48\n",
      "epoch train loss = 0.008279, epoch test loss = 0.014736, Time 00:00:19\n",
      "Acc = 0.883691, mIou = 0.417101\n",
      "epoch 49, 0/65,train loss is 0.008981983177363873\n",
      "epoch 49, 15/65,train loss is 0.008997288532555103\n",
      "epoch 49, 30/65,train loss is 0.008883927948772907\n",
      "epoch 49, 45/65,train loss is 0.005491346586495638\n",
      "epoch 49, 60/65,train loss is 0.004946553148329258\n",
      "<---------------------------------------------------->\n",
      "epoch: 49\n",
      "epoch train loss = 0.007841, epoch test loss = 0.013358, Time 00:00:19\n",
      "Acc = 0.941387, mIou = 0.676911\n",
      "saveing checkpoints/model_50.pth\n",
      "epoch 50, 0/65,train loss is 0.004499257542192936\n",
      "epoch 50, 15/65,train loss is 0.0067757898941636086\n",
      "epoch 50, 30/65,train loss is 0.007697514723986387\n",
      "epoch 50, 45/65,train loss is 0.006866591051220894\n",
      "epoch 50, 60/65,train loss is 0.010659408755600452\n",
      "<---------------------------------------------------->\n",
      "epoch: 50\n",
      "epoch train loss = 0.007530, epoch test loss = 0.014015, Time 00:00:19\n",
      "Acc = 0.948389, mIou = 0.776181\n",
      "epoch 51, 0/65,train loss is 0.006570506375283003\n",
      "epoch 51, 15/65,train loss is 0.008220271207392216\n",
      "epoch 51, 30/65,train loss is 0.006768141873180866\n",
      "epoch 51, 45/65,train loss is 0.0066413963213562965\n",
      "epoch 51, 60/65,train loss is 0.0056938291527330875\n",
      "<---------------------------------------------------->\n",
      "epoch: 51\n",
      "epoch train loss = 0.007608, epoch test loss = 0.016597, Time 00:00:19\n",
      "Acc = 0.914023, mIou = 0.540007\n",
      "epoch 52, 0/65,train loss is 0.005257788579910994\n",
      "epoch 52, 15/65,train loss is 0.008153961971402168\n",
      "epoch 52, 30/65,train loss is 0.005905291996896267\n",
      "epoch 52, 45/65,train loss is 0.010425044223666191\n",
      "epoch 52, 60/65,train loss is 0.005590030923485756\n",
      "<---------------------------------------------------->\n",
      "epoch: 52\n",
      "epoch train loss = 0.008097, epoch test loss = 0.013865, Time 00:00:19\n",
      "Acc = 0.959121, mIou = 0.537546\n",
      "epoch 53, 0/65,train loss is 0.008957887068390846\n",
      "epoch 53, 15/65,train loss is 0.005775435362011194\n",
      "epoch 53, 30/65,train loss is 0.005584606900811195\n",
      "epoch 53, 45/65,train loss is 0.006579556502401829\n",
      "epoch 53, 60/65,train loss is 0.009243392385542393\n",
      "<---------------------------------------------------->\n",
      "epoch: 53\n",
      "epoch train loss = 0.007547, epoch test loss = 0.014315, Time 00:00:19\n",
      "Acc = 0.932393, mIou = 0.494089\n",
      "epoch 54, 0/65,train loss is 0.008515013381838799\n",
      "epoch 54, 15/65,train loss is 0.005143930669873953\n",
      "epoch 54, 30/65,train loss is 0.005067619029432535\n",
      "epoch 54, 45/65,train loss is 0.006229869555681944\n",
      "epoch 54, 60/65,train loss is 0.009112066589295864\n",
      "<---------------------------------------------------->\n",
      "epoch: 54\n",
      "epoch train loss = 0.007243, epoch test loss = 0.013573, Time 00:00:19\n",
      "Acc = 0.930596, mIou = 0.736633\n",
      "saveing checkpoints/model_55.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 之前模型中断，加载参数后继续继续训练\n",
    "model = DeepLabV3P(3,3)\n",
    "model_path='./checkpoints/deeplabv3p_Focalloss_45.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "train(model,epo_num=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v1.15.1-92d9ed92\n",
      "INFO:root:Using OBS-Python-SDK-3.1.2\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy_parallel('/home/ma-user/work/checkpoints/deeplabv3p_Focalloss_55.pth',\n",
    "                       'obs://class-1275-42687/Lab-2210/modelarts22926584/deeplabv3p_Focalloss_55.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
